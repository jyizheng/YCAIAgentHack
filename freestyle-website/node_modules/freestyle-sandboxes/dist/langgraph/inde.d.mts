import { F as FreestyleExecuteScriptParamsConfiguration } from '../types.gen-CG8tIO9M.js';
import * as z3 from 'zod/v3';
import { z } from 'zod/v3';
import * as z4 from 'zod/v4/core';

type AgentAction = {
    tool: string;
    toolInput: string | Record<string, any>;
    log: string;
};
type AgentFinish = {
    returnValues: Record<string, any>;
    log: string;
};

type InteropZodType<Output = any, Input = Output> = z3.ZodType<Output, z3.ZodTypeDef, Input> | z4.$ZodType<Output, Input>;
type InferInteropZodInput<T> = T extends z3.ZodType<unknown, z3.ZodTypeDef, infer Input> ? Input : T extends z4.$ZodType<unknown, infer Input> ? Input : T extends {
    _zod: {
        input: infer Input;
    };
} ? Input : never;
type InferInteropZodOutput<T> = T extends z3.ZodType<infer Output, z3.ZodTypeDef, unknown> ? Output : T extends z4.$ZodType<infer Output, unknown> ? Output : T extends {
    _zod: {
        output: infer Output;
    };
} ? Output : never;

type ChainValues = Record<string, any>;

interface SerializedFields {
    [key: string]: any;
}

interface BaseSerialized<T extends string> {
    lc: number;
    type: T;
    id: string[];
    name?: string;
    graph?: Record<string, any>;
}
interface SerializedConstructor extends BaseSerialized<"constructor"> {
    kwargs: SerializedFields;
}
interface SerializedSecret extends BaseSerialized<"secret"> {
}
interface SerializedNotImplemented extends BaseSerialized<"not_implemented"> {
}
type Serialized = SerializedConstructor | SerializedSecret | SerializedNotImplemented;
interface SerializableInterface {
    get lc_id(): string[];
}
declare abstract class Serializable implements SerializableInterface {
    lc_serializable: boolean;
    lc_kwargs: SerializedFields;
    /**
     * A path to the module that contains the class, eg. ["langchain", "llms"]
     * Usually should be the same as the entrypoint the class is exported from.
     */
    abstract lc_namespace: string[];
    /**
     * The name of the serializable. Override to provide an alias or
     * to preserve the serialized module name in minified environments.
     *
     * Implemented as a static method to support loading logic.
     */
    static lc_name(): string;
    /**
     * The final serialized identifier for the module.
     */
    get lc_id(): string[];
    /**
     * A map of secrets, which will be omitted from serialization.
     * Keys are paths to the secret in constructor args, e.g. "foo.bar.baz".
     * Values are the secret ids, which will be used when deserializing.
     */
    get lc_secrets(): {
        [key: string]: string;
    } | undefined;
    /**
     * A map of additional attributes to merge with constructor args.
     * Keys are the attribute names, e.g. "foo".
     * Values are the attribute values, which will be serialized.
     * These attributes need to be accepted by the constructor as arguments.
     */
    get lc_attributes(): SerializedFields | undefined;
    /**
     * A map of aliases for constructor args.
     * Keys are the attribute names, e.g. "foo".
     * Values are the alias that will replace the key in serialization.
     * This is used to eg. make argument names match Python.
     */
    get lc_aliases(): {
        [key: string]: string;
    } | undefined;
    /**
     * A manual list of keys that should be serialized.
     * If not overridden, all fields passed into the constructor will be serialized.
     */
    get lc_serializable_keys(): string[] | undefined;
    constructor(kwargs?: SerializedFields, ..._args: never[]);
    toJSON(): Serialized;
    toJSONNotImplemented(): SerializedNotImplemented;
}

interface StoredMessageData {
    content: string;
    role: string | undefined;
    name: string | undefined;
    tool_call_id: string | undefined;
    additional_kwargs?: Record<string, any>;
    /** Response metadata. For example: response headers, logprobs, token counts, model name. */
    response_metadata?: Record<string, any>;
    id?: string;
}
interface StoredMessage {
    type: string;
    data: StoredMessageData;
}
type MessageType = "human" | "ai" | "generic" | "developer" | "system" | "function" | "tool" | "remove";
type ImageDetail = "auto" | "low" | "high";
type MessageContentText = {
    type: "text";
    text: string;
};
type MessageContentImageUrl = {
    type: "image_url";
    image_url: string | {
        url: string;
        detail?: ImageDetail;
    };
};
type MessageContentComplex = MessageContentText | MessageContentImageUrl | (Record<string, any> & {
    type?: "text" | "image_url" | string;
}) | (Record<string, any> & {
    type?: never;
});
type MessageContent = string | MessageContentComplex[];
interface FunctionCall {
    /**
     * The arguments to call the function with, as generated by the model in JSON
     * format. Note that the model does not always generate valid JSON, and may
     * hallucinate parameters not defined by your function schema. Validate the
     * arguments in your code before calling your function.
     */
    arguments: string;
    /**
     * The name of the function to call.
     */
    name: string;
}
type BaseMessageFields = {
    content: MessageContent;
    name?: string;
    additional_kwargs?: {
        /**
         * @deprecated Use "tool_calls" field on AIMessages instead
         */
        function_call?: FunctionCall;
        /**
         * @deprecated Use "tool_calls" field on AIMessages instead
         */
        tool_calls?: OpenAIToolCall[];
        [key: string]: unknown;
    };
    /** Response metadata. For example: response headers, logprobs, token counts, model name. */
    response_metadata?: Record<string, any>;
    /**
     * An optional unique identifier for the message. This should ideally be
     * provided by the provider/model which created the message.
     */
    id?: string;
};
/**
 * Base class for all types of messages in a conversation. It includes
 * properties like `content`, `name`, and `additional_kwargs`. It also
 * includes methods like `toDict()` and `_getType()`.
 */
declare abstract class BaseMessage extends Serializable implements BaseMessageFields {
    lc_namespace: string[];
    lc_serializable: boolean;
    get lc_aliases(): Record<string, string>;
    /**
     * Get text content of the message.
     */
    get text(): string;
    /** The content of the message. */
    content: MessageContent;
    /** The name of the message sender in a multi-user chat. */
    name?: string;
    /** Additional keyword arguments */
    additional_kwargs: NonNullable<BaseMessageFields["additional_kwargs"]>;
    /** Response metadata. For example: response headers, logprobs, token counts, model name. */
    response_metadata: NonNullable<BaseMessageFields["response_metadata"]>;
    /**
     * An optional unique identifier for the message. This should ideally be
     * provided by the provider/model which created the message.
     */
    id?: string;
    /**
     * @deprecated Use .getType() instead or import the proper typeguard.
     * For example:
     *
     * ```ts
     * import { isAIMessage } from "@langchain/core/messages";
     *
     * const message = new AIMessage("Hello!");
     * isAIMessage(message); // true
     * ```
     */
    abstract _getType(): MessageType;
    /** The type of the message. */
    getType(): MessageType;
    constructor(fields: string | BaseMessageFields, 
    /** @deprecated */
    kwargs?: Record<string, unknown>);
    toDict(): StoredMessage;
    static lc_name(): string;
    get _printableFields(): Record<string, unknown>;
    _updateId(value: string | undefined): void;
    get [Symbol.toStringTag](): any;
}
/**
 * @deprecated Use "tool_calls" field on AIMessages instead
 */
type OpenAIToolCall = {
    /**
     * The ID of the tool call.
     */
    id: string;
    /**
     * The function that the model called.
     */
    function: FunctionCall;
    /**
     * The type of the tool. Currently, only `function` is supported.
     */
    type: "function";
    index?: number;
};
/**
 * Represents a chunk of a message, which can be concatenated with other
 * message chunks. It includes a method `_merge_kwargs_dict()` for merging
 * additional keyword arguments from another `BaseMessageChunk` into this
 * one. It also overrides the `__add__()` method to support concatenation
 * of `BaseMessageChunk` instances.
 */
declare abstract class BaseMessageChunk extends BaseMessage {
    abstract concat(chunk: BaseMessageChunk): BaseMessageChunk;
}

declare const RUN_KEY = "__run";
/**
 * Output of a single generation.
 */
interface Generation {
    /**
     * Generated text output
     */
    text: string;
    /**
     * Raw generation info response from the provider.
     * May include things like reason for finishing (e.g. in {@link OpenAI})
     */
    generationInfo?: Record<string, any>;
}
type GenerationChunkFields = {
    text: string;
    generationInfo?: Record<string, any>;
};
/**
 * Chunk of a single generation. Used for streaming.
 */
declare class GenerationChunk implements Generation {
    text: string;
    generationInfo?: Record<string, any>;
    constructor(fields: GenerationChunkFields);
    concat(chunk: GenerationChunk): GenerationChunk;
}
/**
 * Contains all relevant information returned by an LLM.
 */
type LLMResult = {
    /**
     * List of the things generated. Each input could have multiple {@link Generation | generations}, hence this is a list of lists.
     */
    generations: Generation[][];
    /**
     * Dictionary of arbitrary LLM-provider specific output.
     */
    llmOutput?: Record<string, any>;
    /**
     * Dictionary of run metadata
     */
    [RUN_KEY]?: Record<string, any>;
};
interface ChatGeneration extends Generation {
    message: BaseMessage;
}
type ChatGenerationChunkFields = GenerationChunkFields & {
    message: BaseMessageChunk;
};
declare class ChatGenerationChunk extends GenerationChunk implements ChatGeneration {
    message: BaseMessageChunk;
    constructor(fields: ChatGenerationChunkFields);
    concat(chunk: ChatGenerationChunk): ChatGenerationChunk;
}

interface DocumentInput<Metadata extends Record<string, any> = Record<string, any>> {
    pageContent: string;
    metadata?: Metadata;
    /**
     * An optional identifier for the document.
     *
     * Ideally this should be unique across the document collection and formatted
     * as a UUID, but this will not be enforced.
     */
    id?: string;
}
interface DocumentInterface<Metadata extends Record<string, any> = Record<string, any>> {
    pageContent: string;
    metadata: Metadata;
    /**
     * An optional identifier for the document.
     *
     * Ideally this should be unique across the document collection and formatted
     * as a UUID, but this will not be enforced.
     */
    id?: string;
}
/**
 * Interface for interacting with a document.
 */
declare class Document<Metadata extends Record<string, any> = Record<string, any>> implements DocumentInput, DocumentInterface {
    pageContent: string;
    metadata: Metadata;
    /**
     * An optional identifier for the document.
     *
     * Ideally this should be unique across the document collection and formatted
     * as a UUID, but this will not be enforced.
     */
    id?: string;
    constructor(fields: DocumentInput<Metadata>);
}

type Error$1 = any;
/**
 * Interface for the input parameters of the BaseCallbackHandler class. It
 * allows to specify which types of events should be ignored by the
 * callback handler.
 */
interface BaseCallbackHandlerInput {
    ignoreLLM?: boolean;
    ignoreChain?: boolean;
    ignoreAgent?: boolean;
    ignoreRetriever?: boolean;
    ignoreCustomEvent?: boolean;
    _awaitHandler?: boolean;
    raiseError?: boolean;
}
/**
 * Interface for the indices of a new token produced by an LLM or Chat
 * Model in streaming mode.
 */
interface NewTokenIndices {
    prompt: number;
    completion: number;
}
type HandleLLMNewTokenCallbackFields = {
    chunk?: GenerationChunk | ChatGenerationChunk;
};
/**
 * Abstract class that provides a set of optional methods that can be
 * overridden in derived classes to handle various events during the
 * execution of a LangChain application.
 */
declare abstract class BaseCallbackHandlerMethodsClass {
    /**
     * Called at the start of an LLM or Chat Model run, with the prompt(s)
     * and the run ID.
     */
    handleLLMStart?(llm: Serialized, prompts: string[], runId: string, parentRunId?: string, extraParams?: Record<string, unknown>, tags?: string[], metadata?: Record<string, unknown>, runName?: string): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    /**
     * Called when an LLM/ChatModel in `streaming` mode produces a new token
     */
    handleLLMNewToken?(token: string, 
    /**
     * idx.prompt is the index of the prompt that produced the token
     *   (if there are multiple prompts)
     * idx.completion is the index of the completion that produced the token
     *   (if multiple completions per prompt are requested)
     */
    idx: NewTokenIndices, runId: string, parentRunId?: string, tags?: string[], fields?: HandleLLMNewTokenCallbackFields): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    /**
     * Called if an LLM/ChatModel run encounters an error
     */
    handleLLMError?(err: Error$1, runId: string, parentRunId?: string, tags?: string[], extraParams?: Record<string, unknown>): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    /**
     * Called at the end of an LLM/ChatModel run, with the output and the run ID.
     */
    handleLLMEnd?(output: LLMResult, runId: string, parentRunId?: string, tags?: string[], extraParams?: Record<string, unknown>): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    /**
     * Called at the start of a Chat Model run, with the prompt(s)
     * and the run ID.
     */
    handleChatModelStart?(llm: Serialized, messages: BaseMessage[][], runId: string, parentRunId?: string, extraParams?: Record<string, unknown>, tags?: string[], metadata?: Record<string, unknown>, runName?: string): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    /**
     * Called at the start of a Chain run, with the chain name and inputs
     * and the run ID.
     */
    handleChainStart?(chain: Serialized, inputs: ChainValues, runId: string, parentRunId?: string, tags?: string[], metadata?: Record<string, unknown>, runType?: string, runName?: string): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    /**
     * Called if a Chain run encounters an error
     */
    handleChainError?(err: Error$1, runId: string, parentRunId?: string, tags?: string[], kwargs?: {
        inputs?: Record<string, unknown>;
    }): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    /**
     * Called at the end of a Chain run, with the outputs and the run ID.
     */
    handleChainEnd?(outputs: ChainValues, runId: string, parentRunId?: string, tags?: string[], kwargs?: {
        inputs?: Record<string, unknown>;
    }): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    /**
     * Called at the start of a Tool run, with the tool name and input
     * and the run ID.
     */
    handleToolStart?(tool: Serialized, input: string, runId: string, parentRunId?: string, tags?: string[], metadata?: Record<string, unknown>, runName?: string): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    /**
     * Called if a Tool run encounters an error
     */
    handleToolError?(err: Error$1, runId: string, parentRunId?: string, tags?: string[]): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    /**
     * Called at the end of a Tool run, with the tool output and the run ID.
     */
    handleToolEnd?(output: any, runId: string, parentRunId?: string, tags?: string[]): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    handleText?(text: string, runId: string, parentRunId?: string, tags?: string[]): Promise<void> | void;
    /**
     * Called when an agent is about to execute an action,
     * with the action and the run ID.
     */
    handleAgentAction?(action: AgentAction, runId: string, parentRunId?: string, tags?: string[]): Promise<void> | void;
    /**
     * Called when an agent finishes execution, before it exits.
     * with the final output and the run ID.
     */
    handleAgentEnd?(action: AgentFinish, runId: string, parentRunId?: string, tags?: string[]): Promise<void> | void;
    handleRetrieverStart?(retriever: Serialized, query: string, runId: string, parentRunId?: string, tags?: string[], metadata?: Record<string, unknown>, name?: string): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    handleRetrieverEnd?(documents: DocumentInterface[], runId: string, parentRunId?: string, tags?: string[]): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    handleRetrieverError?(err: Error$1, runId: string, parentRunId?: string, tags?: string[]): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
    handleCustomEvent?(eventName: string, data: any, runId: string, tags?: string[], metadata?: Record<string, any>): // eslint-disable-next-line @typescript-eslint/no-explicit-any
    Promise<any> | any;
}
/**
 * Base interface for callbacks. All methods are optional. If a method is not
 * implemented, it will be ignored. If a method is implemented, it will be
 * called at the appropriate time. All methods are called with the run ID of
 * the LLM/ChatModel/Chain that is running, which is generated by the
 * CallbackManager.
 *
 * @interface
 */
type CallbackHandlerMethods = BaseCallbackHandlerMethodsClass;
/**
 * Interface for handlers that can indicate a preference for streaming responses.
 * When implemented, this allows the handler to signal whether it prefers to receive
 * streaming responses from language models rather than complete responses.
 */
interface CallbackHandlerPrefersStreaming {
    readonly lc_prefer_streaming: boolean;
}
/**
 * Abstract base class for creating callback handlers in the LangChain
 * framework. It provides a set of optional methods that can be overridden
 * in derived classes to handle various events during the execution of a
 * LangChain application.
 */
declare abstract class BaseCallbackHandler extends BaseCallbackHandlerMethodsClass implements BaseCallbackHandlerInput, Serializable {
    lc_serializable: boolean;
    get lc_namespace(): ["langchain_core", "callbacks", string];
    get lc_secrets(): {
        [key: string]: string;
    } | undefined;
    get lc_attributes(): {
        [key: string]: string;
    } | undefined;
    get lc_aliases(): {
        [key: string]: string;
    } | undefined;
    get lc_serializable_keys(): string[] | undefined;
    /**
     * The name of the serializable. Override to provide an alias or
     * to preserve the serialized module name in minified environments.
     *
     * Implemented as a static method to support loading logic.
     */
    static lc_name(): string;
    /**
     * The final serialized identifier for the module.
     */
    get lc_id(): string[];
    lc_kwargs: SerializedFields;
    abstract name: string;
    ignoreLLM: boolean;
    ignoreChain: boolean;
    ignoreAgent: boolean;
    ignoreRetriever: boolean;
    ignoreCustomEvent: boolean;
    raiseError: boolean;
    awaitHandlers: boolean;
    constructor(input?: BaseCallbackHandlerInput);
    copy(): BaseCallbackHandler;
    toJSON(): Serialized;
    toJSONNotImplemented(): SerializedNotImplemented;
    static fromMethods(methods: CallbackHandlerMethods): {
        name: string;
        lc_serializable: boolean;
        readonly lc_namespace: ["langchain_core", "callbacks", string];
        readonly lc_secrets: {
            [key: string]: string;
        } | undefined;
        readonly lc_attributes: {
            [key: string]: string;
        } | undefined;
        readonly lc_aliases: {
            [key: string]: string;
        } | undefined;
        readonly lc_serializable_keys: string[] | undefined;
        /**
         * The final serialized identifier for the module.
         */
        readonly lc_id: string[];
        lc_kwargs: SerializedFields;
        ignoreLLM: boolean;
        ignoreChain: boolean;
        ignoreAgent: boolean;
        ignoreRetriever: boolean;
        ignoreCustomEvent: boolean;
        raiseError: boolean;
        awaitHandlers: boolean;
        copy(): BaseCallbackHandler;
        toJSON(): Serialized;
        toJSONNotImplemented(): SerializedNotImplemented;
        /**
         * Called at the start of an LLM or Chat Model run, with the prompt(s)
         * and the run ID.
         */
        handleLLMStart?(llm: Serialized, prompts: string[], runId: string, parentRunId?: string, extraParams?: Record<string, unknown>, tags?: string[], metadata?: Record<string, unknown>, runName?: string): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        /**
         * Called when an LLM/ChatModel in `streaming` mode produces a new token
         */
        handleLLMNewToken?(token: string, idx: NewTokenIndices, runId: string, parentRunId?: string, tags?: string[], fields?: HandleLLMNewTokenCallbackFields): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        /**
         * Called if an LLM/ChatModel run encounters an error
         */
        handleLLMError?(err: Error$1, runId: string, parentRunId?: string, tags?: string[], extraParams?: Record<string, unknown>): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        /**
         * Called at the end of an LLM/ChatModel run, with the output and the run ID.
         */
        handleLLMEnd?(output: LLMResult, runId: string, parentRunId?: string, tags?: string[], extraParams?: Record<string, unknown>): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        /**
         * Called at the start of a Chat Model run, with the prompt(s)
         * and the run ID.
         */
        handleChatModelStart?(llm: Serialized, messages: BaseMessage[][], runId: string, parentRunId?: string, extraParams?: Record<string, unknown>, tags?: string[], metadata?: Record<string, unknown>, runName?: string): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        /**
         * Called at the start of a Chain run, with the chain name and inputs
         * and the run ID.
         */
        handleChainStart?(chain: Serialized, inputs: ChainValues, runId: string, parentRunId?: string, tags?: string[], metadata?: Record<string, unknown>, runType?: string, runName?: string): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        /**
         * Called if a Chain run encounters an error
         */
        handleChainError?(err: Error$1, runId: string, parentRunId?: string, tags?: string[], kwargs?: {
            inputs?: Record<string, unknown>;
        }): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        /**
         * Called at the end of a Chain run, with the outputs and the run ID.
         */
        handleChainEnd?(outputs: ChainValues, runId: string, parentRunId?: string, tags?: string[], kwargs?: {
            inputs?: Record<string, unknown>;
        }): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        /**
         * Called at the start of a Tool run, with the tool name and input
         * and the run ID.
         */
        handleToolStart?(tool: Serialized, input: string, runId: string, parentRunId?: string, tags?: string[], metadata?: Record<string, unknown>, runName?: string): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        /**
         * Called if a Tool run encounters an error
         */
        handleToolError?(err: Error$1, runId: string, parentRunId?: string, tags?: string[]): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        /**
         * Called at the end of a Tool run, with the tool output and the run ID.
         */
        handleToolEnd?(output: any, runId: string, parentRunId?: string, tags?: string[]): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        handleText?(text: string, runId: string, parentRunId?: string, tags?: string[]): Promise<void> | void;
        /**
         * Called when an agent is about to execute an action,
         * with the action and the run ID.
         */
        handleAgentAction?(action: AgentAction, runId: string, parentRunId?: string, tags?: string[]): Promise<void> | void;
        /**
         * Called when an agent finishes execution, before it exits.
         * with the final output and the run ID.
         */
        handleAgentEnd?(action: AgentFinish, runId: string, parentRunId?: string, tags?: string[]): Promise<void> | void;
        handleRetrieverStart?(retriever: Serialized, query: string, runId: string, parentRunId?: string, tags?: string[], metadata?: Record<string, unknown>, name?: string): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        handleRetrieverEnd?(documents: DocumentInterface[], runId: string, parentRunId?: string, tags?: string[]): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        handleRetrieverError?(err: Error$1, runId: string, parentRunId?: string, tags?: string[]): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
        handleCustomEvent?(eventName: string, data: any, runId: string, tags?: string[], metadata?: Record<string, any>): // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Promise<any> | any;
    };
}

type ResponseCallback = (response?: Response) => Promise<boolean>;
interface AsyncCallerParams {
    /**
     * The maximum number of concurrent calls that can be made.
     * Defaults to `Infinity`, which means no limit.
     */
    maxConcurrency?: number;
    /**
     * The maximum number of retries that can be made for a single call,
     * with an exponential backoff between each attempt. Defaults to 6.
     */
    maxRetries?: number;
    onFailedResponseHook?: ResponseCallback;
    debug?: boolean;
}

interface TracerSession {
    tenant_id: string;
    id: string;
    start_time: number;
    end_time?: number;
    description?: string;
    name?: string;
    /** Extra metadata for the project. */
    extra?: KVMap;
    reference_dataset_id?: string;
}
interface TracerSessionResult extends TracerSession {
    run_count?: number;
    latency_p50?: number;
    latency_p99?: number;
    total_tokens?: number;
    prompt_tokens?: number;
    completion_tokens?: number;
    last_run_start_time?: number;
    feedback_stats?: Record<string, unknown>;
    run_facets?: KVMap[];
}
type KVMap = Record<string, any>;
type ScoreType = number | boolean | null;
type ValueType = number | boolean | string | object | null;
type DataType = "kv" | "llm" | "chat";
interface BaseExample {
    dataset_id: string;
    inputs: KVMap;
    outputs?: KVMap;
    metadata?: KVMap;
    source_run_id?: string;
}
interface AttachmentInfo {
    presigned_url: string;
    mime_type?: string;
}
type AttachmentData = Uint8Array | ArrayBuffer;
type AttachmentDescription = {
    mimeType: string;
    data: AttachmentData;
};
type Attachments = Record<string, [
    string,
    AttachmentData
] | AttachmentDescription>;
/**
 * A run can represent either a trace (root run)
 * or a child run (~span).
 */
interface BaseRun {
    /** Optionally, a unique identifier for the run. */
    id?: string;
    /** A human-readable name for the run. */
    name: string;
    /** The epoch time at which the run started, if available. */
    start_time?: number | string;
    /** Specifies the type of run (tool, chain, llm, etc.). */
    run_type: string;
    /** The epoch time at which the run ended, if applicable. */
    end_time?: number | string;
    /** Any additional metadata or settings for the run. */
    extra?: KVMap;
    /** Error message, captured if the run faces any issues. */
    error?: string;
    /** Serialized state of the run for potential future use. */
    serialized?: object;
    /** Events like 'start', 'end' linked to the run. */
    events?: KVMap[];
    /** Inputs that were used to initiate the run. */
    inputs: KVMap;
    /** Outputs produced by the run, if any. */
    outputs?: KVMap;
    /** ID of an example that might be related to this run. */
    reference_example_id?: string;
    /** ID of a parent run, if this run is part of a larger operation. */
    parent_run_id?: string;
    /** Tags for further categorizing or annotating the run. */
    tags?: string[];
    /** Unique ID assigned to every run within this nested trace. **/
    trace_id?: string;
    /**
     * The dotted order for the run.
     *
     * This is a string composed of {time}{run-uuid}.* so that a trace can be
     * sorted in the order it was executed.
     *
     * Example:
     * - Parent: 20230914T223155647Z1b64098b-4ab7-43f6-afee-992304f198d8
     * - Children:
     *    - 20230914T223155647Z1b64098b-4ab7-43f6-afee-992304f198d8.20230914T223155649Z809ed3a2-0172-4f4d-8a02-a64e9b7a0f8a
     *   - 20230915T223155647Z1b64098b-4ab7-43f6-afee-992304f198d8.20230914T223155650Zc8d9f4c5-6c5a-4b2d-9b1c-3d9d7a7c5c7c
     */
    dotted_order?: string;
    /**
     * Attachments associated with the run.
     * Each entry is a tuple of [mime_type, bytes]
     */
    attachments?: Attachments;
}
type S3URL = {
    ROOT: {
        /** A pre-signed URL */
        presigned_url: string;
        /** The S3 path to the object in storage */
        s3_url: string;
    };
};
/**
 * Describes properties of a run when loaded from the database.
 * Extends the BaseRun interface.
 */
interface Run$1 extends BaseRun {
    /** A unique identifier for the run, mandatory when loaded from DB. */
    id: string;
    /** The ID of the project that owns this run. */
    session_id?: string;
    /** IDs of any child runs spawned by this run. */
    child_run_ids?: string[];
    /** Child runs, loaded explicitly via a heavier query. */
    child_runs?: Run$1[];
    /** Stats capturing feedback for this run. */
    feedback_stats?: KVMap;
    /** The URL path where this run is accessible within the app. */
    app_path?: string;
    /** The manifest ID that correlates with this run. */
    manifest_id?: string;
    /** The current status of the run, such as 'success'. */
    status?: string;
    /** Number of tokens used in the prompt. */
    prompt_tokens?: number;
    /** Number of tokens generated in the completion. */
    completion_tokens?: number;
    /** Total token count, combining prompt and completion. */
    total_tokens?: number;
    /** Time when the first token was processed. */
    first_token_time?: number;
    /** IDs of parent runs, if multiple exist. */
    parent_run_ids?: string[];
    /** Whether the run is included in a dataset. */
    in_dataset?: boolean;
    /** The output S3 URLs */
    outputs_s3_urls?: S3URL;
    /** The input S3 URLs */
    inputs_s3_urls?: S3URL;
}
interface RunCreate extends BaseRun {
    revision_id?: string;
    child_runs?: this[];
    session_name?: string;
}
interface RunUpdate {
    id?: string;
    end_time?: number | string;
    extra?: KVMap;
    tags?: string[];
    error?: string;
    inputs?: KVMap;
    outputs?: KVMap;
    parent_run_id?: string;
    reference_example_id?: string;
    events?: KVMap[];
    session_id?: string;
    session_name?: string;
    /** Unique ID assigned to every run within this nested trace. **/
    trace_id?: string;
    /**
     * The dotted order for the run.
     *
     * This is a string composed of {time}{run-uuid}.* so that a trace can be
     * sorted in the order it was executed.
     *
     * Example:
     * - Parent: 20230914T223155647Z1b64098b-4ab7-43f6-afee-992304f198d8
     * - Children:
     *    - 20230914T223155647Z1b64098b-4ab7-43f6-afee-992304f198d8.20230914T223155649Z809ed3a2-0172-4f4d-8a02-a64e9b7a0f8a
     *   - 20230915T223155647Z1b64098b-4ab7-43f6-afee-992304f198d8.20230914T223155650Zc8d9f4c5-6c5a-4b2d-9b1c-3d9d7a7c5c7c
     */
    dotted_order?: string;
    /**
     * Attachments associated with the run.
     * Each entry is a tuple of [mime_type, bytes]
     */
    attachments?: Attachments;
}
interface ExampleCreate {
    id?: string;
    inputs: KVMap;
    outputs?: KVMap;
    metadata?: KVMap;
    split?: string | string[];
    attachments?: Attachments;
    created_at?: string;
    dataset_id?: string;
    dataset_name?: string;
    source_run_id?: string;
    use_source_run_io?: boolean;
    use_source_run_attachments?: string[];
}
interface ExampleUpdate {
    id: string;
    inputs?: KVMap;
    outputs?: KVMap;
    metadata?: KVMap;
    split?: string | string[];
    attachments?: Attachments;
    attachments_operations?: KVMap;
    dataset_id?: string;
}
interface ExampleUpdateWithoutId extends Omit<ExampleUpdate, "id"> {
}
interface UploadExamplesResponse {
    count: number;
    example_ids: string[];
}
interface UpdateExamplesResponse extends UploadExamplesResponse {
}
interface Example extends BaseExample {
    id: string;
    created_at: string;
    modified_at?: string;
    source_run_id?: string;
    runs: Run$1[];
    attachments?: Record<string, AttachmentInfo>;
    split?: string | string[];
}
interface ExampleSearch extends BaseExample {
    id: string;
}
interface BaseDataset {
    name: string;
    description: string;
    tenant_id: string;
    data_type?: DataType;
    inputs_schema_definition?: KVMap;
    outputs_schema_definition?: KVMap;
}
interface Dataset extends BaseDataset {
    id: string;
    created_at: string;
    modified_at: string;
    example_count?: number;
    session_count?: number;
    last_session_start_time?: number;
}
interface DatasetShareSchema {
    dataset_id: string;
    share_token: string;
    url: string;
}
interface DatasetVersion {
    tags?: string[];
    as_of: string;
}
interface FeedbackSourceBase {
    type: string;
    metadata?: KVMap;
}
interface APIFeedbackSource extends FeedbackSourceBase {
    type: "api";
}
interface ModelFeedbackSource extends FeedbackSourceBase {
    type: "model";
}
interface FeedbackBase {
    created_at: string;
    modified_at: string;
    run_id: string;
    key: string;
    score: ScoreType;
    value: ValueType;
    comment: string | null;
    correction: string | object | null;
    feedback_source: APIFeedbackSource | ModelFeedbackSource | KVMap | null;
}
interface Feedback extends FeedbackBase {
    id: string;
}
interface LangChainBaseMessage {
    _getType: () => string;
    content: string;
    additional_kwargs?: KVMap;
}
interface FeedbackIngestToken {
    id: string;
    url: string;
    expires_at: string;
}
interface TimeDelta {
    days?: number;
    hours?: number;
    minutes?: number;
}
interface FeedbackCategory {
    value: number;
    label?: string | null;
}
/**
 * Represents the configuration for feedback.
 * This determines how the LangSmith service interprets feedback
 * values of the associated key.
 */
interface FeedbackConfig {
    /**
     * The type of feedback.
     * - "continuous": Feedback with a continuous numeric.
     * - "categorical": Feedback with a categorical value (classes)
     * - "freeform": Feedback with a freeform text value (notes).
     */
    type: "continuous" | "categorical" | "freeform";
    /**
     * The minimum value for continuous feedback.
     */
    min?: number | null;
    /**
     * The maximum value for continuous feedback.
     */
    max?: number | null;
    /**
     * The categories for categorical feedback.
     * Each category can be a string or an object with additional properties.
     *
     * If feedback is categorical, this defines the valid categories the server will accept.
     * Not applicable to continuous or freeform feedback types.
     */
    categories?: FeedbackCategory[] | null;
}
interface DatasetDiffInfo {
    examples_modified: string[];
    examples_added: string[];
    examples_removed: string[];
}
interface ComparativeExperiment {
    id: string;
    name: string;
    description: string;
    tenant_id: string;
    created_at: string;
    modified_at: string;
    reference_dataset_id: string;
    extra?: Record<string, unknown>;
    experiments_info?: Array<Record<string, unknown>>;
    feedback_stats?: Record<string, unknown>;
}
interface PromptCommit {
    owner: string;
    repo: string;
    commit_hash: string;
    manifest: Record<string, any>;
    examples: Array<Record<any, any>>;
}
interface Prompt {
    repo_handle: string;
    description?: string;
    readme?: string;
    id: string;
    tenant_id: string;
    created_at: string;
    updated_at: string;
    is_public: boolean;
    is_archived: boolean;
    tags: string[];
    original_repo_id?: string;
    upstream_repo_id?: string;
    owner?: string;
    full_name: string;
    num_likes: number;
    num_downloads: number;
    num_views: number;
    liked_by_auth_user: boolean;
    last_commit_hash?: string;
    num_commits: number;
    original_repo_full_name?: string;
    upstream_repo_full_name?: string;
}
type PromptSortField = "num_downloads" | "num_views" | "updated_at" | "num_likes";
interface LikePromptResponse {
    likes: number;
}
interface LangSmithSettings {
    id: string;
    display_name: string;
    created_at: string;
    tenant_handle?: string;
}
interface AnnotationQueue {
    /** The unique identifier of the annotation queue. */
    id: string;
    /** The name of the annotation queue. */
    name: string;
    /** An optional description of the annotation queue. */
    description?: string;
    /** The timestamp when the annotation queue was created. */
    created_at: string;
    /** The timestamp when the annotation queue was last updated. */
    updated_at: string;
    /** The ID of the tenant associated with the annotation queue. */
    tenant_id: string;
}
interface AnnotationQueueWithDetails extends AnnotationQueue {
    /** The rubric instructions for the annotation queue. */
    rubric_instructions?: string;
}
interface RunWithAnnotationQueueInfo extends BaseRun {
    /** The last time this run was reviewed. */
    last_reviewed_time?: string;
    /** The time this run was added to the queue. */
    added_at?: string;
}

interface RunTreeConfig {
    name: string;
    run_type?: string;
    id?: string;
    project_name?: string;
    parent_run?: RunTree;
    parent_run_id?: string;
    child_runs?: RunTree[];
    start_time?: number | string;
    end_time?: number | string;
    extra?: KVMap;
    metadata?: KVMap;
    tags?: string[];
    error?: string;
    serialized?: object;
    inputs?: KVMap;
    outputs?: KVMap;
    reference_example_id?: string;
    client?: Client;
    tracingEnabled?: boolean;
    on_end?: (runTree: RunTree) => void;
    execution_order?: number;
    child_execution_order?: number;
    trace_id?: string;
    dotted_order?: string;
    attachments?: Attachments;
    replicas?: Replica[];
}
interface RunnableConfigLike {
    /**
     * Tags for this call and any sub-calls (eg. a Chain calling an LLM).
     * You can use these to filter calls.
     */
    tags?: string[];
    /**
     * Metadata for this call and any sub-calls (eg. a Chain calling an LLM).
     * Keys should be strings, values should be JSON-serializable.
     */
    metadata?: Record<string, unknown>;
    /**
     * Callbacks for this call and any sub-calls (eg. a Chain calling an LLM).
     * Tags are passed to all callbacks, metadata is passed to handle*Start callbacks.
     */
    callbacks?: any;
}
interface HeadersLike {
    get(name: string): string | null;
    set(name: string, value: string): void;
}
type ProjectReplica = [string, KVMap | undefined];
type WriteReplica = {
    apiUrl?: string;
    apiKey?: string;
    projectName?: string;
    updates?: KVMap | undefined;
    fromEnv?: boolean;
};
type Replica = ProjectReplica | WriteReplica;
declare class RunTree implements BaseRun {
    private static sharedClient;
    id: string;
    name: RunTreeConfig["name"];
    run_type: string;
    project_name: string;
    parent_run?: RunTree;
    parent_run_id?: string;
    child_runs: RunTree[];
    start_time: number;
    end_time?: number;
    extra: KVMap;
    tags?: string[];
    error?: string;
    serialized: object;
    inputs: KVMap;
    outputs?: KVMap;
    reference_example_id?: string;
    client: Client;
    events?: KVMap[] | undefined;
    trace_id: string;
    dotted_order: string;
    tracingEnabled?: boolean;
    execution_order: number;
    child_execution_order: number;
    /**
     * Attachments associated with the run.
     * Each entry is a tuple of [mime_type, bytes]
     */
    attachments?: Attachments;
    /**
     * Projects to replicate this run to with optional updates.
     */
    replicas?: WriteReplica[];
    private _serialized_start_time;
    constructor(originalConfig: RunTreeConfig | RunTree);
    set metadata(metadata: KVMap);
    get metadata(): KVMap;
    private static getDefaultConfig;
    static getSharedClient(): Client;
    createChild(config: RunTreeConfig): RunTree;
    end(outputs?: KVMap, error?: string, endTime?: number, metadata?: KVMap): Promise<void>;
    private _convertToCreate;
    private _remapForProject;
    postRun(excludeChildRuns?: boolean): Promise<void>;
    patchRun(): Promise<void>;
    toJSON(): RunCreate & {
        id: string;
    };
    /**
     * Add an event to the run tree.
     * @param event - A single event or string to add
     */
    addEvent(event: RunEvent | string): void;
    static fromRunnableConfig(parentConfig: RunnableConfigLike, props: RunTreeConfig): RunTree;
    static fromDottedOrder(dottedOrder: string): RunTree | undefined;
    static fromHeaders(headers: Record<string, string | string[]> | HeadersLike, inheritArgs?: RunTreeConfig): RunTree | undefined;
    toHeaders(headers?: HeadersLike): {
        "langsmith-trace": string;
        baggage: string;
    };
}
interface RunEvent {
    name?: string;
    time?: string;
    message?: string;
    kwargs?: Record<string, unknown>;
    [key: string]: unknown;
}

/**
 * Represents the result of an evaluation.
 */
type EvaluationResult = {
    /**
     * The key associated with the evaluation result.
     */
    key: string;
    /**
     * The score of the evaluation result.
     */
    score?: ScoreType;
    /**
     * The value of the evaluation result.
     */
    value?: ValueType;
    /**
     * A comment associated with the evaluation result.
     */
    comment?: string;
    /**
     * A correction record associated with the evaluation result.
     */
    correction?: Record<string, unknown>;
    /**
     * Information about the evaluator.
     */
    evaluatorInfo?: Record<string, unknown>;
    /**
     * The source run ID of the evaluation result.
     * If set, a link to the source run will be available in the UI.
     */
    sourceRunId?: string;
    /**
     * The target run ID of the evaluation result.
     * If this is not set, the target run ID is assumed to be
     * the root of the trace.
     */
    targetRunId?: string;
    /**
     * The feedback config associated with the evaluation result.
     * If set, this will be used to define how a feedback key
     * should be interpreted.
     */
    feedbackConfig?: FeedbackConfig;
};
/**
 * Batch evaluation results, if your evaluator wishes
 * to return multiple scores.
 */
type EvaluationResults = {
    /**
     * The evaluation results.
     */
    results: Array<EvaluationResult>;
};
interface RunEvaluator {
    evaluateRun(run: Run$1, example?: Example, options?: Partial<RunTreeConfig>): Promise<EvaluationResult | EvaluationResults>;
}

interface ClientConfig {
    apiUrl?: string;
    apiKey?: string;
    callerOptions?: AsyncCallerParams;
    timeout_ms?: number;
    webUrl?: string;
    anonymizer?: (values: KVMap) => KVMap | Promise<KVMap>;
    hideInputs?: boolean | ((inputs: KVMap) => KVMap | Promise<KVMap>);
    hideOutputs?: boolean | ((outputs: KVMap) => KVMap | Promise<KVMap>);
    autoBatchTracing?: boolean;
    batchSizeBytesLimit?: number;
    blockOnRootRunFinalization?: boolean;
    traceBatchConcurrency?: number;
    fetchOptions?: RequestInit;
    /**
     * Whether to require manual .flush() calls before sending traces.
     * Useful if encountering network rate limits at trace high volumes.
     */
    manualFlushMode?: boolean;
    tracingSamplingRate?: number;
    /**
     * Enable debug mode for the client. If set, all sent HTTP requests will be logged.
     */
    debug?: boolean;
}
/**
 * Represents the parameters for listing runs (spans) from the Langsmith server.
 */
interface ListRunsParams {
    /**
     * The ID or IDs of the project(s) to filter by.
     */
    projectId?: string | string[];
    /**
     * The name or names of the project(s) to filter by.
     */
    projectName?: string | string[];
    /**
     * The ID of the trace to filter by.
     */
    traceId?: string;
    /**
     * isRoot - Whether to only include root runs.
     *  */
    isRoot?: boolean;
    /**
     * The execution order to filter by.
     */
    executionOrder?: number;
    /**
     * The ID of the parent run to filter by.
     */
    parentRunId?: string;
    /**
     * The order by run start date
     */
    order?: "asc" | "desc";
    /**
     * The ID of the reference example to filter by.
     */
    referenceExampleId?: string;
    /**
     * The start time to filter by.
     */
    startTime?: Date;
    /**
     * The run type to filter by.
     */
    runType?: string;
    /**
     * Indicates whether to filter by error runs.
     */
    error?: boolean;
    /**
     * The ID or IDs of the runs to filter by.
     */
    id?: string[];
    /**
     * The maximum number of runs to retrieve.
     */
    limit?: number;
    /**
     * The query string to filter by.
     */
    query?: string;
    /**
     * The filter string to apply.
     *
     * Run Filtering:
     * Listing runs with query params is useful for simple queries, but doesn't support many common needs, such as filtering by metadata, tags, or other fields.
     * LangSmith supports a filter query language to permit more complex filtering operations when fetching runs. This guide will provide a high level overview of the grammar as well as a few examples of when it can be useful.
     * If you'd prefer a more visual guide, you can get a taste of the language by viewing the table of runs on any of your projects' pages. We provide some recommended filters to get you started that you can copy and use the SDK.
     *
     * Grammar:
     * The filtering grammar is based on common comparators on fields in the run object. Supported comparators include:
     * - gte (greater than or equal to)
     * - gt (greater than)
     * - lte (less than or equal to)
     * - lt (less than)
     * - eq (equal to)
     * - neq (not equal to)
     * - has (check if run contains a tag or metadata json blob)
     * - search (search for a substring in a string field)
     */
    filter?: string;
    /**
     * Filter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular
     *  `filter` parameter to let you filter runs by attributes of the root run within a trace. Example is filtering by
     * feedback assigned to the trace.
     */
    traceFilter?: string;
    /**
     * Filter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in
     * conjunction with the regular `filter` parameter to let you filter runs by attributes of any run within a trace.
     */
    treeFilter?: string;
    /**
     * The values to include in the response.
     */
    select?: string[];
}
interface GroupRunsParams {
    /**
     * The ID or IDs of the project(s) to filter by.
     */
    projectId?: string;
    /**
     * The ID or IDs of the project(s) to filter by.
     */
    projectName?: string;
    /**
     * @example "conversation"
     */
    groupBy: string;
    /**
     * The filter string to apply.
     *
     * Run Filtering:
     * Listing runs with query params is useful for simple queries, but doesn't support many common needs, such as filtering by metadata, tags, or other fields.
     * LangSmith supports a filter query language to permit more complex filtering operations when fetching runs. This guide will provide a high level overview of the grammar as well as a few examples of when it can be useful.
     * If you'd prefer a more visual guide, you can get a taste of the language by viewing the table of runs on any of your projects' pages. We provide some recommended filters to get you started that you can copy and use the SDK.
     *
     * Grammar:
     * The filtering grammar is based on common comparators on fields in the run object. Supported comparators include:
     * - gte (greater than or equal to)
     * - gt (greater than)
     * - lte (less than or equal to)
     * - lt (less than)
     * - eq (equal to)
     * - neq (not equal to)
     * - has (check if run contains a tag or metadata json blob)
     * - search (search for a substring in a string field)
     */
    filter?: string;
    /**
     * The start time to filter by.
     */
    startTime?: Date;
    /**
     * The end time to filter by.
     */
    endTime?: Date;
    /**
     * The maximum number of runs to retrieve.
     */
    limit?: number;
    /**
     * The maximum number of runs to retrieve.
     */
    offset?: number;
}
interface UploadCSVParams {
    csvFile: Blob;
    fileName: string;
    inputKeys: string[];
    outputKeys: string[];
    description?: string;
    dataType?: DataType;
    name?: string;
}
interface CreateRunParams {
    name: string;
    inputs: KVMap;
    run_type: string;
    id?: string;
    start_time?: number | string;
    end_time?: number | string;
    extra?: KVMap;
    error?: string;
    serialized?: object;
    outputs?: KVMap;
    reference_example_id?: string;
    child_runs?: RunCreate[];
    parent_run_id?: string;
    project_name?: string;
    revision_id?: string;
    trace_id?: string;
    dotted_order?: string;
    attachments?: Attachments;
}
interface ProjectOptions {
    projectName?: string;
    projectId?: string;
}
type RecordStringAny = Record<string, any>;
type FeedbackSourceType = "model" | "api" | "app";
type CreateExampleOptions = {
    /** The ID of the dataset to create the example in. */
    datasetId?: string;
    /** The name of the dataset to create the example in (if dataset ID is not provided). */
    datasetName?: string;
    /** The creation date of the example. */
    createdAt?: Date;
    /** A unique identifier for the example. */
    exampleId?: string;
    /** Additional metadata associated with the example. */
    metadata?: KVMap;
    /** The split(s) to assign the example to. */
    split?: string | string[];
    /** The ID of the source run associated with this example. */
    sourceRunId?: string;
    /** Whether to use the inputs and outputs from the source run. */
    useSourceRunIO?: boolean;
    /** Which attachments from the source run to use. */
    useSourceRunAttachments?: string[];
    /** Attachments for the example */
    attachments?: Attachments;
};
type CreateProjectParams = {
    projectName: string;
    description?: string | null;
    metadata?: RecordStringAny | null;
    upsert?: boolean;
    projectExtra?: RecordStringAny | null;
    referenceDatasetId?: string | null;
};
type Thread = {
    filter: string;
    count: number;
    total_tokens: number;
    total_cost: number | null;
    min_start_time: string;
    max_start_time: string;
    latency_p50: number;
    latency_p99: number;
    feedback_stats: any | null;
    group_key: string;
    first_inputs: string;
    last_outputs: string;
    last_error: string | null;
};
declare class Client implements LangSmithTracingClientInterface {
    private apiKey?;
    private apiUrl;
    private webUrl?;
    private caller;
    private batchIngestCaller;
    private timeout_ms;
    private _tenantId;
    private hideInputs?;
    private hideOutputs?;
    private tracingSampleRate?;
    private filteredPostUuids;
    private autoBatchTracing;
    private autoBatchQueue;
    private autoBatchTimeout;
    private autoBatchAggregationDelayMs;
    private batchSizeBytesLimit?;
    private fetchOptions;
    private settings;
    private blockOnRootRunFinalization;
    private traceBatchConcurrency;
    private _serverInfo;
    private _getServerInfoPromise?;
    private manualFlushMode;
    private langSmithToOTELTranslator?;
    private multipartStreamingDisabled;
    debug: boolean;
    constructor(config?: ClientConfig);
    static getDefaultClientConfig(): {
        apiUrl: string;
        apiKey?: string;
        webUrl?: string;
        hideInputs?: boolean;
        hideOutputs?: boolean;
    };
    getHostUrl(): string;
    private get headers();
    private _getPlatformEndpointPath;
    private processInputs;
    private processOutputs;
    private prepareRunCreateOrUpdateInputs;
    private _getResponse;
    private _get;
    private _getPaginated;
    private _getCursorPaginatedList;
    private _shouldSample;
    private _filterForSampling;
    private _getBatchSizeLimitBytes;
    private _getMultiPartSupport;
    private drainAutoBatchQueue;
    private _processBatch;
    private _sendBatchToOTELTranslator;
    private processRunOperation;
    protected _getServerInfo(): Promise<any>;
    protected _ensureServerInfo(): Promise<Record<string, any>>;
    protected _getSettings(): Promise<LangSmithSettings>;
    /**
     * Flushes current queued traces.
     */
    flush(): Promise<void>;
    private _cloneCurrentOTELContext;
    createRun(run: CreateRunParams, options?: {
        apiKey?: string;
        apiUrl?: string;
    }): Promise<void>;
    /**
     * Batch ingest/upsert multiple runs in the Langsmith system.
     * @param runs
     */
    batchIngestRuns({ runCreates, runUpdates, }: {
        runCreates?: RunCreate[];
        runUpdates?: RunUpdate[];
    }, options?: {
        apiKey?: string;
        apiUrl?: string;
    }): Promise<void>;
    private _postBatchIngestRuns;
    /**
     * Batch ingest/upsert multiple runs in the Langsmith system.
     * @param runs
     */
    multipartIngestRuns({ runCreates, runUpdates, }: {
        runCreates?: RunCreate[];
        runUpdates?: RunUpdate[];
    }, options?: {
        apiKey?: string;
        apiUrl?: string;
    }): Promise<void>;
    private _createNodeFetchBody;
    private _createMultipartStream;
    private _sendMultipartRequest;
    updateRun(runId: string, run: RunUpdate, options?: {
        apiKey?: string;
        apiUrl?: string;
    }): Promise<void>;
    readRun(runId: string, { loadChildRuns }?: {
        loadChildRuns: boolean;
    }): Promise<Run$1>;
    getRunUrl({ runId, run, projectOpts, }: {
        runId?: string;
        run?: Run$1;
        projectOpts?: ProjectOptions;
    }): Promise<string>;
    private _loadChildRuns;
    /**
     * List runs from the LangSmith server.
     * @param projectId - The ID of the project to filter by.
     * @param projectName - The name of the project to filter by.
     * @param parentRunId - The ID of the parent run to filter by.
     * @param traceId - The ID of the trace to filter by.
     * @param referenceExampleId - The ID of the reference example to filter by.
     * @param startTime - The start time to filter by.
     * @param isRoot - Indicates whether to only return root runs.
     * @param runType - The run type to filter by.
     * @param error - Indicates whether to filter by error runs.
     * @param id - The ID of the run to filter by.
     * @param query - The query string to filter by.
     * @param filter - The filter string to apply to the run spans.
     * @param traceFilter - The filter string to apply on the root run of the trace.
     * @param treeFilter - The filter string to apply on other runs in the trace.
     * @param limit - The maximum number of runs to retrieve.
     * @returns {AsyncIterable<Run>} - The runs.
     *
     * @example
     * // List all runs in a project
     * const projectRuns = client.listRuns({ projectName: "<your_project>" });
     *
     * @example
     * // List LLM and Chat runs in the last 24 hours
     * const todaysLLMRuns = client.listRuns({
     *   projectName: "<your_project>",
     *   start_time: new Date(Date.now() - 24 * 60 * 60 * 1000),
     *   run_type: "llm",
     * });
     *
     * @example
     * // List traces in a project
     * const rootRuns = client.listRuns({
     *   projectName: "<your_project>",
     *   execution_order: 1,
     * });
     *
     * @example
     * // List runs without errors
     * const correctRuns = client.listRuns({
     *   projectName: "<your_project>",
     *   error: false,
     * });
     *
     * @example
     * // List runs by run ID
     * const runIds = [
     *   "a36092d2-4ad5-4fb4-9c0d-0dba9a2ed836",
     *   "9398e6be-964f-4aa4-8ae9-ad78cd4b7074",
     * ];
     * const selectedRuns = client.listRuns({ run_ids: runIds });
     *
     * @example
     * // List all "chain" type runs that took more than 10 seconds and had `total_tokens` greater than 5000
     * const chainRuns = client.listRuns({
     *   projectName: "<your_project>",
     *   filter: 'and(eq(run_type, "chain"), gt(latency, 10), gt(total_tokens, 5000))',
     * });
     *
     * @example
     * // List all runs called "extractor" whose root of the trace was assigned feedback "user_score" score of 1
     * const goodExtractorRuns = client.listRuns({
     *   projectName: "<your_project>",
     *   filter: 'eq(name, "extractor")',
     *   traceFilter: 'and(eq(feedback_key, "user_score"), eq(feedback_score, 1))',
     * });
     *
     * @example
     * // List all runs that started after a specific timestamp and either have "error" not equal to null or a "Correctness" feedback score equal to 0
     * const complexRuns = client.listRuns({
     *   projectName: "<your_project>",
     *   filter: 'and(gt(start_time, "2023-07-15T12:34:56Z"), or(neq(error, null), and(eq(feedback_key, "Correctness"), eq(feedback_score, 0.0))))',
     * });
     *
     * @example
     * // List all runs where `tags` include "experimental" or "beta" and `latency` is greater than 2 seconds
     * const taggedRuns = client.listRuns({
     *   projectName: "<your_project>",
     *   filter: 'and(or(has(tags, "experimental"), has(tags, "beta")), gt(latency, 2))',
     * });
     */
    listRuns(props: ListRunsParams): AsyncIterable<Run$1>;
    listGroupRuns(props: GroupRunsParams): AsyncIterable<Thread>;
    getRunStats({ id, trace, parentRun, runType, projectNames, projectIds, referenceExampleIds, startTime, endTime, error, query, filter, traceFilter, treeFilter, isRoot, dataSourceType, }: {
        id?: string[];
        trace?: string;
        parentRun?: string;
        runType?: string;
        projectNames?: string[];
        projectIds?: string[];
        referenceExampleIds?: string[];
        startTime?: string;
        endTime?: string;
        error?: boolean;
        query?: string;
        filter?: string;
        traceFilter?: string;
        treeFilter?: string;
        isRoot?: boolean;
        dataSourceType?: string;
    }): Promise<any>;
    shareRun(runId: string, { shareId }?: {
        shareId?: string;
    }): Promise<string>;
    unshareRun(runId: string): Promise<void>;
    readRunSharedLink(runId: string): Promise<string | undefined>;
    listSharedRuns(shareToken: string, { runIds, }?: {
        runIds?: string[];
    }): Promise<Run$1[]>;
    readDatasetSharedSchema(datasetId?: string, datasetName?: string): Promise<DatasetShareSchema>;
    shareDataset(datasetId?: string, datasetName?: string): Promise<DatasetShareSchema>;
    unshareDataset(datasetId: string): Promise<void>;
    readSharedDataset(shareToken: string): Promise<Dataset>;
    /**
     * Get shared examples.
     *
     * @param {string} shareToken The share token to get examples for. A share token is the UUID (or LangSmith URL, including UUID) generated when explicitly marking an example as public.
     * @param {Object} [options] Additional options for listing the examples.
     * @param {string[] | undefined} [options.exampleIds] A list of example IDs to filter by.
     * @returns {Promise<Example[]>} The shared examples.
     */
    listSharedExamples(shareToken: string, options?: {
        exampleIds?: string[];
    }): Promise<Example[]>;
    createProject({ projectName, description, metadata, upsert, projectExtra, referenceDatasetId, }: CreateProjectParams): Promise<TracerSession>;
    updateProject(projectId: string, { name, description, metadata, projectExtra, endTime, }: {
        name?: string | null;
        description?: string | null;
        metadata?: RecordStringAny | null;
        projectExtra?: RecordStringAny | null;
        endTime?: string | null;
    }): Promise<TracerSession>;
    hasProject({ projectId, projectName, }: {
        projectId?: string;
        projectName?: string;
    }): Promise<boolean>;
    readProject({ projectId, projectName, includeStats, }: {
        projectId?: string;
        projectName?: string;
        includeStats?: boolean;
    }): Promise<TracerSessionResult>;
    getProjectUrl({ projectId, projectName, }: {
        projectId?: string;
        projectName?: string;
    }): Promise<string>;
    getDatasetUrl({ datasetId, datasetName, }: {
        datasetId?: string;
        datasetName?: string;
    }): Promise<string>;
    private _getTenantId;
    listProjects({ projectIds, name, nameContains, referenceDatasetId, referenceDatasetName, referenceFree, metadata, }?: {
        projectIds?: string[];
        name?: string;
        nameContains?: string;
        referenceDatasetId?: string;
        referenceDatasetName?: string;
        referenceFree?: boolean;
        metadata?: RecordStringAny;
    }): AsyncIterable<TracerSession>;
    deleteProject({ projectId, projectName, }: {
        projectId?: string;
        projectName?: string;
    }): Promise<void>;
    uploadCsv({ csvFile, fileName, inputKeys, outputKeys, description, dataType, name, }: UploadCSVParams): Promise<Dataset>;
    createDataset(name: string, { description, dataType, inputsSchema, outputsSchema, metadata, }?: {
        description?: string;
        dataType?: DataType;
        inputsSchema?: KVMap;
        outputsSchema?: KVMap;
        metadata?: RecordStringAny;
    }): Promise<Dataset>;
    readDataset({ datasetId, datasetName, }: {
        datasetId?: string;
        datasetName?: string;
    }): Promise<Dataset>;
    hasDataset({ datasetId, datasetName, }: {
        datasetId?: string;
        datasetName?: string;
    }): Promise<boolean>;
    diffDatasetVersions({ datasetId, datasetName, fromVersion, toVersion, }: {
        datasetId?: string;
        datasetName?: string;
        fromVersion: string | Date;
        toVersion: string | Date;
    }): Promise<DatasetDiffInfo>;
    readDatasetOpenaiFinetuning({ datasetId, datasetName, }: {
        datasetId?: string;
        datasetName?: string;
    }): Promise<any[]>;
    listDatasets({ limit, offset, datasetIds, datasetName, datasetNameContains, metadata, }?: {
        limit?: number;
        offset?: number;
        datasetIds?: string[];
        datasetName?: string;
        datasetNameContains?: string;
        metadata?: RecordStringAny;
    }): AsyncIterable<Dataset>;
    /**
     * Update a dataset
     * @param props The dataset details to update
     * @returns The updated dataset
     */
    updateDataset(props: {
        datasetId?: string;
        datasetName?: string;
        name?: string;
        description?: string;
    }): Promise<Dataset>;
    /**
     * Updates a tag on a dataset.
     *
     * If the tag is already assigned to a different version of this dataset,
     * the tag will be moved to the new version. The as_of parameter is used to
     * determine which version of the dataset to apply the new tags to.
     *
     * It must be an exact version of the dataset to succeed. You can
     * use the "readDatasetVersion" method to find the exact version
     * to apply the tags to.
     * @param params.datasetId The ID of the dataset to update. Must be provided if "datasetName" is not provided.
     * @param params.datasetName The name of the dataset to update. Must be provided if "datasetId" is not provided.
     * @param params.asOf The timestamp of the dataset to apply the new tags to.
     * @param params.tag The new tag to apply to the dataset.
     */
    updateDatasetTag(props: {
        datasetId?: string;
        datasetName?: string;
        asOf: string | Date;
        tag: string;
    }): Promise<void>;
    deleteDataset({ datasetId, datasetName, }: {
        datasetId?: string;
        datasetName?: string;
    }): Promise<void>;
    indexDataset({ datasetId, datasetName, tag, }: {
        datasetId?: string;
        datasetName?: string;
        tag?: string;
    }): Promise<void>;
    /**
     * Lets you run a similarity search query on a dataset.
     *
     * Requires the dataset to be indexed. Please see the `indexDataset` method to set up indexing.
     *
     * @param inputs      The input on which to run the similarity search. Must have the
     *                    same schema as the dataset.
     *
     * @param datasetId   The dataset to search for similar examples.
     *
     * @param limit       The maximum number of examples to return. Will return the top `limit` most
     *                    similar examples in order of most similar to least similar. If no similar
     *                    examples are found, random examples will be returned.
     *
     * @param filter      A filter string to apply to the search. Only examples will be returned that
     *                    match the filter string. Some examples of filters
     *
     *                    - eq(metadata.mykey, "value")
     *                    - and(neq(metadata.my.nested.key, "value"), neq(metadata.mykey, "value"))
     *                    - or(eq(metadata.mykey, "value"), eq(metadata.mykey, "othervalue"))
     *
     * @returns           A list of similar examples.
     *
     *
     * @example
     * dataset_id = "123e4567-e89b-12d3-a456-426614174000"
     * inputs = {"text": "How many people live in Berlin?"}
     * limit = 5
     * examples = await client.similarExamples(inputs, dataset_id, limit)
     */
    similarExamples(inputs: KVMap, datasetId: string, limit: number, { filter, }?: {
        filter?: string;
    }): Promise<ExampleSearch[]>;
    createExample(update: ExampleCreate): Promise<Example>;
    /**
     * @deprecated This signature is deprecated, use createExample(update: ExampleCreate) instead
     */
    createExample(inputs: KVMap, outputs: KVMap, options: CreateExampleOptions): Promise<Example>;
    createExamples(uploads: ExampleCreate[]): Promise<Example[]>;
    /** @deprecated Use the uploads-only overload instead */
    createExamples(props: {
        inputs?: Array<KVMap>;
        outputs?: Array<KVMap>;
        metadata?: Array<KVMap>;
        splits?: Array<string | Array<string>>;
        sourceRunIds?: Array<string>;
        useSourceRunIOs?: Array<boolean>;
        useSourceRunAttachments?: Array<string[]>;
        attachments?: Array<Attachments>;
        exampleIds?: Array<string>;
        datasetId?: string;
        datasetName?: string;
    }): Promise<Example[]>;
    createLLMExample(input: string, generation: string | undefined, options: CreateExampleOptions): Promise<Example>;
    createChatExample(input: KVMap[] | LangChainBaseMessage[], generations: KVMap | LangChainBaseMessage | undefined, options: CreateExampleOptions): Promise<Example>;
    readExample(exampleId: string): Promise<Example>;
    listExamples({ datasetId, datasetName, exampleIds, asOf, splits, inlineS3Urls, metadata, limit, offset, filter, includeAttachments, }?: {
        datasetId?: string;
        datasetName?: string;
        exampleIds?: string[];
        asOf?: string | Date;
        splits?: string[];
        inlineS3Urls?: boolean;
        metadata?: KVMap;
        limit?: number;
        offset?: number;
        filter?: string;
        includeAttachments?: boolean;
    }): AsyncIterable<Example>;
    deleteExample(exampleId: string): Promise<void>;
    /**
     * @deprecated This signature is deprecated, use updateExample(update: ExampleUpdate) instead
     */
    updateExample(exampleId: string, update: ExampleUpdateWithoutId): Promise<object>;
    updateExample(update: ExampleUpdate): Promise<object>;
    updateExamples(update: ExampleUpdate[]): Promise<object>;
    /**
     * Get dataset version by closest date or exact tag.
     *
     * Use this to resolve the nearest version to a given timestamp or for a given tag.
     *
     * @param options The options for getting the dataset version
     * @param options.datasetId The ID of the dataset
     * @param options.datasetName The name of the dataset
     * @param options.asOf The timestamp of the dataset to retrieve
     * @param options.tag The tag of the dataset to retrieve
     * @returns The dataset version
     */
    readDatasetVersion({ datasetId, datasetName, asOf, tag, }: {
        datasetId?: string;
        datasetName?: string;
        asOf?: string | Date;
        tag?: string;
    }): Promise<DatasetVersion>;
    listDatasetSplits({ datasetId, datasetName, asOf, }: {
        datasetId?: string;
        datasetName?: string;
        asOf?: string | Date;
    }): Promise<string[]>;
    updateDatasetSplits({ datasetId, datasetName, splitName, exampleIds, remove, }: {
        datasetId?: string;
        datasetName?: string;
        splitName: string;
        exampleIds: string[];
        remove?: boolean;
    }): Promise<void>;
    /**
     * @deprecated This method is deprecated and will be removed in future LangSmith versions, use `evaluate` from `langsmith/evaluation` instead.
     */
    evaluateRun(run: Run$1 | string, evaluator: RunEvaluator, { sourceInfo, loadChildRuns, referenceExample, }?: {
        sourceInfo?: KVMap;
        loadChildRuns: boolean;
        referenceExample?: Example;
    }): Promise<Feedback>;
    createFeedback(runId: string | null, key: string, { score, value, correction, comment, sourceInfo, feedbackSourceType, sourceRunId, feedbackId, feedbackConfig, projectId, comparativeExperimentId, }: {
        score?: ScoreType;
        value?: ValueType;
        correction?: object;
        comment?: string;
        sourceInfo?: object;
        feedbackSourceType?: FeedbackSourceType;
        feedbackConfig?: FeedbackConfig;
        sourceRunId?: string;
        feedbackId?: string;
        eager?: boolean;
        projectId?: string;
        comparativeExperimentId?: string;
    }): Promise<Feedback>;
    updateFeedback(feedbackId: string, { score, value, correction, comment, }: {
        score?: number | boolean | null;
        value?: number | boolean | string | object | null;
        correction?: object | null;
        comment?: string | null;
    }): Promise<void>;
    readFeedback(feedbackId: string): Promise<Feedback>;
    deleteFeedback(feedbackId: string): Promise<void>;
    listFeedback({ runIds, feedbackKeys, feedbackSourceTypes, }?: {
        runIds?: string[];
        feedbackKeys?: string[];
        feedbackSourceTypes?: FeedbackSourceType[];
    }): AsyncIterable<Feedback>;
    /**
     * Creates a presigned feedback token and URL.
     *
     * The token can be used to authorize feedback metrics without
     * needing an API key. This is useful for giving browser-based
     * applications the ability to submit feedback without needing
     * to expose an API key.
     *
     * @param runId The ID of the run.
     * @param feedbackKey The feedback key.
     * @param options Additional options for the token.
     * @param options.expiration The expiration time for the token.
     *
     * @returns A promise that resolves to a FeedbackIngestToken.
     */
    createPresignedFeedbackToken(runId: string, feedbackKey: string, { expiration, feedbackConfig, }?: {
        expiration?: string | TimeDelta;
        feedbackConfig?: FeedbackConfig;
    }): Promise<FeedbackIngestToken>;
    createComparativeExperiment({ name, experimentIds, referenceDatasetId, createdAt, description, metadata, id, }: {
        name: string;
        experimentIds: Array<string>;
        referenceDatasetId?: string;
        createdAt?: Date;
        description?: string;
        metadata?: Record<string, unknown>;
        id?: string;
    }): Promise<ComparativeExperiment>;
    /**
     * Retrieves a list of presigned feedback tokens for a given run ID.
     * @param runId The ID of the run.
     * @returns An async iterable of FeedbackIngestToken objects.
     */
    listPresignedFeedbackTokens(runId: string): AsyncIterable<FeedbackIngestToken>;
    _selectEvalResults(results: EvaluationResult | EvaluationResult[] | EvaluationResults): Array<EvaluationResult>;
    _logEvaluationFeedback(evaluatorResponse: EvaluationResult | EvaluationResult[] | EvaluationResults, run?: Run$1, sourceInfo?: {
        [key: string]: any;
    }): Promise<[results: EvaluationResult[], feedbacks: Feedback[]]>;
    logEvaluationFeedback(evaluatorResponse: EvaluationResult | EvaluationResult[] | EvaluationResults, run?: Run$1, sourceInfo?: {
        [key: string]: any;
    }): Promise<EvaluationResult[]>;
    /**
     * API for managing annotation queues
     */
    /**
     * List the annotation queues on the LangSmith API.
     * @param options - The options for listing annotation queues
     * @param options.queueIds - The IDs of the queues to filter by
     * @param options.name - The name of the queue to filter by
     * @param options.nameContains - The substring that the queue name should contain
     * @param options.limit - The maximum number of queues to return
     * @returns An iterator of AnnotationQueue objects
     */
    listAnnotationQueues(options?: {
        queueIds?: string[];
        name?: string;
        nameContains?: string;
        limit?: number;
    }): AsyncIterableIterator<AnnotationQueue>;
    /**
     * Create an annotation queue on the LangSmith API.
     * @param options - The options for creating an annotation queue
     * @param options.name - The name of the annotation queue
     * @param options.description - The description of the annotation queue
     * @param options.queueId - The ID of the annotation queue
     * @returns The created AnnotationQueue object
     */
    createAnnotationQueue(options: {
        name: string;
        description?: string;
        queueId?: string;
        rubricInstructions?: string;
    }): Promise<AnnotationQueueWithDetails>;
    /**
     * Read an annotation queue with the specified queue ID.
     * @param queueId - The ID of the annotation queue to read
     * @returns The AnnotationQueueWithDetails object
     */
    readAnnotationQueue(queueId: string): Promise<AnnotationQueueWithDetails>;
    /**
     * Update an annotation queue with the specified queue ID.
     * @param queueId - The ID of the annotation queue to update
     * @param options - The options for updating the annotation queue
     * @param options.name - The new name for the annotation queue
     * @param options.description - The new description for the annotation queue
     */
    updateAnnotationQueue(queueId: string, options: {
        name: string;
        description?: string;
        rubricInstructions?: string;
    }): Promise<void>;
    /**
     * Delete an annotation queue with the specified queue ID.
     * @param queueId - The ID of the annotation queue to delete
     */
    deleteAnnotationQueue(queueId: string): Promise<void>;
    /**
     * Add runs to an annotation queue with the specified queue ID.
     * @param queueId - The ID of the annotation queue
     * @param runIds - The IDs of the runs to be added to the annotation queue
     */
    addRunsToAnnotationQueue(queueId: string, runIds: string[]): Promise<void>;
    /**
     * Get a run from an annotation queue at the specified index.
     * @param queueId - The ID of the annotation queue
     * @param index - The index of the run to retrieve
     * @returns A Promise that resolves to a RunWithAnnotationQueueInfo object
     * @throws {Error} If the run is not found at the given index or for other API-related errors
     */
    getRunFromAnnotationQueue(queueId: string, index: number): Promise<RunWithAnnotationQueueInfo>;
    /**
     * Delete a run from an an annotation queue.
     * @param queueId - The ID of the annotation queue to delete the run from
     * @param queueRunId - The ID of the run to delete from the annotation queue
     */
    deleteRunFromAnnotationQueue(queueId: string, queueRunId: string): Promise<void>;
    /**
     * Get the size of an annotation queue.
     * @param queueId - The ID of the annotation queue
     */
    getSizeFromAnnotationQueue(queueId: string): Promise<{
        size: number;
    }>;
    protected _currentTenantIsOwner(owner: string): Promise<boolean>;
    protected _ownerConflictError(action: string, owner: string): Promise<Error>;
    protected _getLatestCommitHash(promptOwnerAndName: string): Promise<string | undefined>;
    protected _likeOrUnlikePrompt(promptIdentifier: string, like: boolean): Promise<LikePromptResponse>;
    protected _getPromptUrl(promptIdentifier: string): Promise<string>;
    promptExists(promptIdentifier: string): Promise<boolean>;
    likePrompt(promptIdentifier: string): Promise<LikePromptResponse>;
    unlikePrompt(promptIdentifier: string): Promise<LikePromptResponse>;
    listCommits(promptOwnerAndName: string): AsyncIterableIterator<PromptCommit>;
    listPrompts(options?: {
        isPublic?: boolean;
        isArchived?: boolean;
        sortField?: PromptSortField;
        query?: string;
    }): AsyncIterableIterator<Prompt>;
    getPrompt(promptIdentifier: string): Promise<Prompt | null>;
    createPrompt(promptIdentifier: string, options?: {
        description?: string;
        readme?: string;
        tags?: string[];
        isPublic?: boolean;
    }): Promise<Prompt>;
    createCommit(promptIdentifier: string, object: any, options?: {
        parentCommitHash?: string;
    }): Promise<string>;
    /**
     * Update examples with attachments using multipart form data.
     * @param updates List of ExampleUpdateWithAttachments objects to upsert
     * @returns Promise with the update response
     */
    updateExamplesMultipart(datasetId: string, updates?: ExampleUpdate[]): Promise<UpdateExamplesResponse>;
    private _updateExamplesMultipart;
    /**
     * Upload examples with attachments using multipart form data.
     * @param uploads List of ExampleUploadWithAttachments objects to upload
     * @returns Promise with the upload response
     * @deprecated This method is deprecated and will be removed in future LangSmith versions, please use `createExamples` instead
     */
    uploadExamplesMultipart(datasetId: string, uploads?: ExampleCreate[]): Promise<UploadExamplesResponse>;
    private _uploadExamplesMultipart;
    updatePrompt(promptIdentifier: string, options?: {
        description?: string;
        readme?: string;
        tags?: string[];
        isPublic?: boolean;
        isArchived?: boolean;
    }): Promise<Record<string, any>>;
    deletePrompt(promptIdentifier: string): Promise<void>;
    pullPromptCommit(promptIdentifier: string, options?: {
        includeModel?: boolean;
    }): Promise<PromptCommit>;
    /**
     * This method should not be used directly, use `import { pull } from "langchain/hub"` instead.
     * Using this method directly returns the JSON string of the prompt rather than a LangChain object.
     * @private
     */
    _pullPrompt(promptIdentifier: string, options?: {
        includeModel?: boolean;
    }): Promise<any>;
    pushPrompt(promptIdentifier: string, options?: {
        object?: any;
        parentCommitHash?: string;
        isPublic?: boolean;
        description?: string;
        readme?: string;
        tags?: string[];
    }): Promise<string>;
    /**
     * Clone a public dataset to your own langsmith tenant.
     * This operation is idempotent. If you already have a dataset with the given name,
     * this function will do nothing.
  
     * @param {string} tokenOrUrl The token of the public dataset to clone.
     * @param {Object} [options] Additional options for cloning the dataset.
     * @param {string} [options.sourceApiUrl] The URL of the langsmith server where the data is hosted. Defaults to the API URL of your current client.
     * @param {string} [options.datasetName] The name of the dataset to create in your tenant. Defaults to the name of the public dataset.
     * @returns {Promise<void>}
     */
    clonePublicDataset(tokenOrUrl: string, options?: {
        sourceApiUrl?: string;
        datasetName?: string;
    }): Promise<void>;
    private parseTokenOrUrl;
    /**
     * Awaits all pending trace batches. Useful for environments where
     * you need to be sure that all tracing requests finish before execution ends,
     * such as serverless environments.
     *
     * @example
     * ```
     * import { Client } from "langsmith";
     *
     * const client = new Client();
     *
     * try {
     *   // Tracing happens here
     *   ...
     * } finally {
     *   await client.awaitPendingTraceBatches();
     * }
     * ```
     *
     * @returns A promise that resolves once all currently pending traces have sent.
     */
    awaitPendingTraceBatches(): Promise<void>;
}
interface LangSmithTracingClientInterface {
    createRun: (run: CreateRunParams) => Promise<void>;
    updateRun: (runId: string, run: RunUpdate) => Promise<void>;
}

interface Run extends BaseRun {
    id: string;
    start_time: number;
    end_time?: number;
    execution_order: number;
    child_runs: this[];
    child_execution_order: number;
    events: Array<{
        name: string;
        time: string;
        kwargs?: Record<string, unknown>;
    }>;
    trace_id?: string;
    dotted_order?: string;
    /** @internal */
    _serialized_start_time?: string;
}
declare abstract class BaseTracer extends BaseCallbackHandler {
    /** @deprecated Use `runTreeMap` instead. */
    protected runMap: Map<string, Run>;
    protected runTreeMap: Map<string, RunTree>;
    protected usesRunTreeMap: boolean;
    constructor(_fields?: BaseCallbackHandlerInput);
    copy(): this;
    protected getRunById(runId?: string): Run | undefined;
    protected stringifyError(error: unknown): string;
    protected abstract persistRun(run: Run): Promise<void>;
    protected _addChildRun(parentRun: Run, childRun: Run): void;
    _addRunToRunMap(run: Run): {
        id: string;
        start_time: number;
        end_time?: number;
        execution_order: number;
        child_runs: Run[];
        child_execution_order: number;
        events: Array<{
            name: string;
            time: string;
            kwargs?: Record<string, unknown>;
        }>;
        trace_id?: string;
        dotted_order?: string;
        /** @internal */
        _serialized_start_time?: string;
        name: string;
        run_type: string;
        extra?: KVMap;
        error?: string;
        serialized?: object;
        inputs: KVMap;
        outputs?: KVMap;
        reference_example_id?: string;
        parent_run_id?: string;
        tags?: string[];
        attachments?: Attachments;
    };
    protected _endTrace(run: Run): Promise<void>;
    protected _getExecutionOrder(parentRunId: string | undefined): number;
    /**
     * Create and add a run to the run map for LLM start events.
     * This must sometimes be done synchronously to avoid race conditions
     * when callbacks are backgrounded, so we expose it as a separate method here.
     */
    _createRunForLLMStart(llm: Serialized, prompts: string[], runId: string, parentRunId?: string, extraParams?: KVMap, tags?: string[], metadata?: KVMap, name?: string): {
        id: string;
        start_time: number;
        end_time?: number;
        execution_order: number;
        child_runs: Run[];
        child_execution_order: number;
        events: Array<{
            name: string;
            time: string;
            kwargs?: Record<string, unknown>;
        }>;
        trace_id?: string;
        dotted_order?: string;
        /** @internal */
        _serialized_start_time?: string;
        name: string;
        run_type: string;
        extra?: KVMap;
        error?: string;
        serialized?: object;
        inputs: KVMap;
        outputs?: KVMap;
        reference_example_id?: string;
        parent_run_id?: string;
        tags?: string[];
        attachments?: Attachments;
    };
    handleLLMStart(llm: Serialized, prompts: string[], runId: string, parentRunId?: string, extraParams?: KVMap, tags?: string[], metadata?: KVMap, name?: string): Promise<Run>;
    /**
     * Create and add a run to the run map for chat model start events.
     * This must sometimes be done synchronously to avoid race conditions
     * when callbacks are backgrounded, so we expose it as a separate method here.
     */
    _createRunForChatModelStart(llm: Serialized, messages: BaseMessage[][], runId: string, parentRunId?: string, extraParams?: KVMap, tags?: string[], metadata?: KVMap, name?: string): {
        id: string;
        start_time: number;
        end_time?: number;
        execution_order: number;
        child_runs: Run[];
        child_execution_order: number;
        events: Array<{
            name: string;
            time: string;
            kwargs?: Record<string, unknown>;
        }>;
        trace_id?: string;
        dotted_order?: string;
        /** @internal */
        _serialized_start_time?: string;
        name: string;
        run_type: string;
        extra?: KVMap;
        error?: string;
        serialized?: object;
        inputs: KVMap;
        outputs?: KVMap;
        reference_example_id?: string;
        parent_run_id?: string;
        tags?: string[];
        attachments?: Attachments;
    };
    handleChatModelStart(llm: Serialized, messages: BaseMessage[][], runId: string, parentRunId?: string, extraParams?: KVMap, tags?: string[], metadata?: KVMap, name?: string): Promise<Run>;
    handleLLMEnd(output: LLMResult, runId: string, _parentRunId?: string, _tags?: string[], extraParams?: Record<string, unknown>): Promise<Run>;
    handleLLMError(error: unknown, runId: string, _parentRunId?: string, _tags?: string[], extraParams?: Record<string, unknown>): Promise<Run>;
    /**
     * Create and add a run to the run map for chain start events.
     * This must sometimes be done synchronously to avoid race conditions
     * when callbacks are backgrounded, so we expose it as a separate method here.
     */
    _createRunForChainStart(chain: Serialized, inputs: ChainValues, runId: string, parentRunId?: string, tags?: string[], metadata?: KVMap, runType?: string, name?: string): {
        id: string;
        start_time: number;
        end_time?: number;
        execution_order: number;
        child_runs: Run[];
        child_execution_order: number;
        events: Array<{
            name: string;
            time: string;
            kwargs?: Record<string, unknown>;
        }>;
        trace_id?: string;
        dotted_order?: string;
        /** @internal */
        _serialized_start_time?: string;
        name: string;
        run_type: string;
        extra?: KVMap;
        error?: string;
        serialized?: object;
        inputs: KVMap;
        outputs?: KVMap;
        reference_example_id?: string;
        parent_run_id?: string;
        tags?: string[];
        attachments?: Attachments;
    };
    handleChainStart(chain: Serialized, inputs: ChainValues, runId: string, parentRunId?: string, tags?: string[], metadata?: KVMap, runType?: string, name?: string): Promise<Run>;
    handleChainEnd(outputs: ChainValues, runId: string, _parentRunId?: string, _tags?: string[], kwargs?: {
        inputs?: Record<string, unknown>;
    }): Promise<Run>;
    handleChainError(error: unknown, runId: string, _parentRunId?: string, _tags?: string[], kwargs?: {
        inputs?: Record<string, unknown>;
    }): Promise<Run>;
    /**
     * Create and add a run to the run map for tool start events.
     * This must sometimes be done synchronously to avoid race conditions
     * when callbacks are backgrounded, so we expose it as a separate method here.
     */
    _createRunForToolStart(tool: Serialized, input: string, runId: string, parentRunId?: string, tags?: string[], metadata?: KVMap, name?: string): {
        id: string;
        start_time: number;
        end_time?: number;
        execution_order: number;
        child_runs: Run[];
        child_execution_order: number;
        events: Array<{
            name: string;
            time: string;
            kwargs?: Record<string, unknown>;
        }>;
        trace_id?: string;
        dotted_order?: string;
        /** @internal */
        _serialized_start_time?: string;
        name: string;
        run_type: string;
        extra?: KVMap;
        error?: string;
        serialized?: object;
        inputs: KVMap;
        outputs?: KVMap;
        reference_example_id?: string;
        parent_run_id?: string;
        tags?: string[];
        attachments?: Attachments;
    };
    handleToolStart(tool: Serialized, input: string, runId: string, parentRunId?: string, tags?: string[], metadata?: KVMap, name?: string): Promise<Run>;
    handleToolEnd(output: any, runId: string): Promise<Run>;
    handleToolError(error: unknown, runId: string): Promise<Run>;
    handleAgentAction(action: AgentAction, runId: string): Promise<void>;
    handleAgentEnd(action: AgentFinish, runId: string): Promise<void>;
    /**
     * Create and add a run to the run map for retriever start events.
     * This must sometimes be done synchronously to avoid race conditions
     * when callbacks are backgrounded, so we expose it as a separate method here.
     */
    _createRunForRetrieverStart(retriever: Serialized, query: string, runId: string, parentRunId?: string, tags?: string[], metadata?: KVMap, name?: string): {
        id: string;
        start_time: number;
        end_time?: number;
        execution_order: number;
        child_runs: Run[];
        child_execution_order: number;
        events: Array<{
            name: string;
            time: string;
            kwargs?: Record<string, unknown>;
        }>;
        trace_id?: string;
        dotted_order?: string;
        /** @internal */
        _serialized_start_time?: string;
        name: string;
        run_type: string;
        extra?: KVMap;
        error?: string;
        serialized?: object;
        inputs: KVMap;
        outputs?: KVMap;
        reference_example_id?: string;
        parent_run_id?: string;
        tags?: string[];
        attachments?: Attachments;
    };
    handleRetrieverStart(retriever: Serialized, query: string, runId: string, parentRunId?: string, tags?: string[], metadata?: KVMap, name?: string): Promise<Run>;
    handleRetrieverEnd(documents: Document<Record<string, unknown>>[], runId: string): Promise<Run>;
    handleRetrieverError(error: unknown, runId: string): Promise<Run>;
    handleText(text: string, runId: string): Promise<void>;
    handleLLMNewToken(token: string, idx: NewTokenIndices, runId: string, _parentRunId?: string, _tags?: string[], fields?: HandleLLMNewTokenCallbackFields): Promise<Run>;
    onRunCreate?(run: Run): void | Promise<void>;
    onRunUpdate?(run: Run): void | Promise<void>;
    onLLMStart?(run: Run): void | Promise<void>;
    onLLMEnd?(run: Run): void | Promise<void>;
    onLLMError?(run: Run): void | Promise<void>;
    onChainStart?(run: Run): void | Promise<void>;
    onChainEnd?(run: Run): void | Promise<void>;
    onChainError?(run: Run): void | Promise<void>;
    onToolStart?(run: Run): void | Promise<void>;
    onToolEnd?(run: Run): void | Promise<void>;
    onToolError?(run: Run): void | Promise<void>;
    onAgentAction?(run: Run): void | Promise<void>;
    onAgentEnd?(run: Run): void | Promise<void>;
    onRetrieverStart?(run: Run): void | Promise<void>;
    onRetrieverEnd?(run: Run): void | Promise<void>;
    onRetrieverError?(run: Run): void | Promise<void>;
    onText?(run: Run): void | Promise<void>;
    onLLMNewToken?(run: Run, token: string, kwargs?: {
        chunk: any;
    }): void | Promise<void>;
}

type BaseCallbackManagerMethods = {
    [K in keyof CallbackHandlerMethods]?: (...args: Parameters<Required<CallbackHandlerMethods>[K]>) => Promise<unknown>;
};
interface CallbackManagerOptions {
    verbose?: boolean;
    tracing?: boolean;
}
type Callbacks = CallbackManager | (BaseCallbackHandler | CallbackHandlerMethods)[];
interface BaseCallbackConfig {
    /**
     * Name for the tracer run for this call. Defaults to the name of the class.
     */
    runName?: string;
    /**
     * Tags for this call and any sub-calls (eg. a Chain calling an LLM).
     * You can use these to filter calls.
     */
    tags?: string[];
    /**
     * Metadata for this call and any sub-calls (eg. a Chain calling an LLM).
     * Keys should be strings, values should be JSON-serializable.
     */
    metadata?: Record<string, unknown>;
    /**
     * Callbacks for this call and any sub-calls (eg. a Chain calling an LLM).
     * Tags are passed to all callbacks, metadata is passed to handle*Start callbacks.
     */
    callbacks?: Callbacks;
    /**
     * Unique identifier for the tracer run for this call. If not provided, a new UUID
     * will be generated.
     */
    runId?: string;
}
/**
 * Manage callbacks from different components of LangChain.
 */
declare abstract class BaseCallbackManager {
    abstract addHandler(handler: BaseCallbackHandler): void;
    abstract removeHandler(handler: BaseCallbackHandler): void;
    abstract setHandlers(handlers: BaseCallbackHandler[]): void;
    setHandler(handler: BaseCallbackHandler): void;
}
/**
 * Base class for run manager in LangChain.
 */
declare class BaseRunManager {
    readonly runId: string;
    readonly handlers: BaseCallbackHandler[];
    protected readonly inheritableHandlers: BaseCallbackHandler[];
    protected readonly tags: string[];
    protected readonly inheritableTags: string[];
    protected readonly metadata: Record<string, unknown>;
    protected readonly inheritableMetadata: Record<string, unknown>;
    protected readonly _parentRunId?: string | undefined;
    constructor(runId: string, handlers: BaseCallbackHandler[], inheritableHandlers: BaseCallbackHandler[], tags: string[], inheritableTags: string[], metadata: Record<string, unknown>, inheritableMetadata: Record<string, unknown>, _parentRunId?: string | undefined);
    get parentRunId(): string | undefined;
    handleText(text: string): Promise<void>;
    handleCustomEvent(eventName: string, data: any, _runId?: string, _tags?: string[], _metadata?: Record<string, any>): Promise<void>;
}
/**
 * Manages callbacks for retriever runs.
 */
declare class CallbackManagerForRetrieverRun extends BaseRunManager implements BaseCallbackManagerMethods {
    getChild(tag?: string): CallbackManager;
    handleRetrieverEnd(documents: DocumentInterface[]): Promise<void>;
    handleRetrieverError(err: Error | unknown): Promise<void>;
}
declare class CallbackManagerForLLMRun extends BaseRunManager implements BaseCallbackManagerMethods {
    handleLLMNewToken(token: string, idx?: NewTokenIndices, _runId?: string, _parentRunId?: string, _tags?: string[], fields?: HandleLLMNewTokenCallbackFields): Promise<void>;
    handleLLMError(err: Error | unknown, _runId?: string, _parentRunId?: string, _tags?: string[], extraParams?: Record<string, unknown>): Promise<void>;
    handleLLMEnd(output: LLMResult, _runId?: string, _parentRunId?: string, _tags?: string[], extraParams?: Record<string, unknown>): Promise<void>;
}
declare class CallbackManagerForChainRun extends BaseRunManager implements BaseCallbackManagerMethods {
    getChild(tag?: string): CallbackManager;
    handleChainError(err: Error | unknown, _runId?: string, _parentRunId?: string, _tags?: string[], kwargs?: {
        inputs?: Record<string, unknown>;
    }): Promise<void>;
    handleChainEnd(output: ChainValues, _runId?: string, _parentRunId?: string, _tags?: string[], kwargs?: {
        inputs?: Record<string, unknown>;
    }): Promise<void>;
    handleAgentAction(action: AgentAction): Promise<void>;
    handleAgentEnd(action: AgentFinish): Promise<void>;
}
declare class CallbackManagerForToolRun extends BaseRunManager implements BaseCallbackManagerMethods {
    getChild(tag?: string): CallbackManager;
    handleToolError(err: Error | unknown): Promise<void>;
    handleToolEnd(output: any): Promise<void>;
}
/**
 * @example
 * ```typescript
 * const prompt = PromptTemplate.fromTemplate("What is the answer to {question}?");
 *
 * // Example of using LLMChain with OpenAI and a simple prompt
 * const chain = new LLMChain({
 *   llm: new ChatOpenAI({ model: "gpt-4o-mini", temperature: 0.9 }),
 *   prompt,
 * });
 *
 * // Running the chain with a single question
 * const result = await chain.call({
 *   question: "What is the airspeed velocity of an unladen swallow?",
 * });
 * console.log("The answer is:", result);
 * ```
 */
declare class CallbackManager extends BaseCallbackManager implements BaseCallbackManagerMethods {
    handlers: BaseCallbackHandler[];
    inheritableHandlers: BaseCallbackHandler[];
    tags: string[];
    inheritableTags: string[];
    metadata: Record<string, unknown>;
    inheritableMetadata: Record<string, unknown>;
    name: string;
    _parentRunId?: string;
    constructor(parentRunId?: string, options?: {
        handlers?: BaseCallbackHandler[];
        inheritableHandlers?: BaseCallbackHandler[];
        tags?: string[];
        inheritableTags?: string[];
        metadata?: Record<string, unknown>;
        inheritableMetadata?: Record<string, unknown>;
    });
    /**
     * Gets the parent run ID, if any.
     *
     * @returns The parent run ID.
     */
    getParentRunId(): string | undefined;
    handleLLMStart(llm: Serialized, prompts: string[], runId?: string | undefined, _parentRunId?: string | undefined, extraParams?: Record<string, unknown> | undefined, _tags?: string[] | undefined, _metadata?: Record<string, unknown> | undefined, runName?: string | undefined): Promise<CallbackManagerForLLMRun[]>;
    handleChatModelStart(llm: Serialized, messages: BaseMessage[][], runId?: string | undefined, _parentRunId?: string | undefined, extraParams?: Record<string, unknown> | undefined, _tags?: string[] | undefined, _metadata?: Record<string, unknown> | undefined, runName?: string | undefined): Promise<CallbackManagerForLLMRun[]>;
    handleChainStart(chain: Serialized, inputs: ChainValues, runId?: string, runType?: string | undefined, _tags?: string[] | undefined, _metadata?: Record<string, unknown> | undefined, runName?: string | undefined): Promise<CallbackManagerForChainRun>;
    handleToolStart(tool: Serialized, input: string, runId?: string, _parentRunId?: string | undefined, _tags?: string[] | undefined, _metadata?: Record<string, unknown> | undefined, runName?: string | undefined): Promise<CallbackManagerForToolRun>;
    handleRetrieverStart(retriever: Serialized, query: string, runId?: string, _parentRunId?: string | undefined, _tags?: string[] | undefined, _metadata?: Record<string, unknown> | undefined, runName?: string | undefined): Promise<CallbackManagerForRetrieverRun>;
    handleCustomEvent?(eventName: string, data: any, runId: string, _tags?: string[], _metadata?: Record<string, any>): Promise<any>;
    addHandler(handler: BaseCallbackHandler, inherit?: boolean): void;
    removeHandler(handler: BaseCallbackHandler): void;
    setHandlers(handlers: BaseCallbackHandler[], inherit?: boolean): void;
    addTags(tags: string[], inherit?: boolean): void;
    removeTags(tags: string[]): void;
    addMetadata(metadata: Record<string, unknown>, inherit?: boolean): void;
    removeMetadata(metadata: Record<string, unknown>): void;
    copy(additionalHandlers?: BaseCallbackHandler[], inherit?: boolean): CallbackManager;
    static fromHandlers(handlers: CallbackHandlerMethods): CallbackManager;
    static configure(inheritableHandlers?: Callbacks, localHandlers?: Callbacks, inheritableTags?: string[], localTags?: string[], inheritableMetadata?: Record<string, unknown>, localMetadata?: Record<string, unknown>, options?: CallbackManagerOptions): CallbackManager | undefined;
    static _configureSync(inheritableHandlers?: Callbacks, localHandlers?: Callbacks, inheritableTags?: string[], localTags?: string[], inheritableMetadata?: Record<string, unknown>, localMetadata?: Record<string, unknown>, options?: CallbackManagerOptions): CallbackManager | undefined;
}

interface BaseDataContentBlock {
    mime_type?: string;
    metadata?: Record<string, unknown>;
}
interface URLContentBlock extends BaseDataContentBlock {
    type: "image" | "audio" | "file";
    source_type: "url";
    url: string;
}
interface Base64ContentBlock extends BaseDataContentBlock {
    type: "image" | "audio" | "file";
    source_type: "base64";
    data: string;
}
interface PlainTextContentBlock extends BaseDataContentBlock {
    type: "file" | "text";
    source_type: "text";
    text: string;
}
interface IDContentBlock extends BaseDataContentBlock {
    type: "image" | "audio" | "file";
    source_type: "id";
    id: string;
}
type DataContentBlock = URLContentBlock | Base64ContentBlock | PlainTextContentBlock | IDContentBlock;

interface ToolMessageFields extends BaseMessageFields {
    content: string | (MessageContentComplex | DataContentBlock)[];
}
interface ToolMessageFieldsWithToolCallId extends ToolMessageFields {
    /**
     * Artifact of the Tool execution which is not meant to be sent to the model.
     *
     * Should only be specified if it is different from the message content, e.g. if only
     * a subset of the full tool output is being passed as message content but the full
     * output is needed in other parts of the code.
     */
    artifact?: any;
    tool_call_id: string;
    /**
     * Status of the tool invocation.
     * @version 0.2.19
     */
    status?: "success" | "error";
}
/**
 * Marker parameter for objects that tools can return directly.
 *
 * If a custom BaseTool is invoked with a ToolCall and the output of custom code is
 * not an instance of DirectToolOutput, the output will automatically be coerced to
 * a string and wrapped in a ToolMessage.
 */
interface DirectToolOutput {
    readonly lc_direct_tool_output: true;
}
/**
 * Represents a tool message in a conversation.
 */
declare class ToolMessage extends BaseMessage implements DirectToolOutput {
    content: string | (MessageContentComplex | DataContentBlock)[];
    static lc_name(): string;
    get lc_aliases(): Record<string, string>;
    lc_direct_tool_output: true;
    /**
     * Status of the tool invocation.
     * @version 0.2.19
     */
    status?: "success" | "error";
    tool_call_id: string;
    /**
     * Artifact of the Tool execution which is not meant to be sent to the model.
     *
     * Should only be specified if it is different from the message content, e.g. if only
     * a subset of the full tool output is being passed as message content but the full
     * output is needed in other parts of the code.
     */
    artifact?: any;
    constructor(fields: ToolMessageFieldsWithToolCallId);
    constructor(fields: string | ToolMessageFields, tool_call_id: string, name?: string);
    _getType(): MessageType;
    static isInstance(message: BaseMessage): message is ToolMessage;
    get _printableFields(): Record<string, unknown>;
}
/**
 * A call to a tool.
 * @property {string} name - The name of the tool to be called
 * @property {Record<string, any>} args - The arguments to the tool call
 * @property {string} [id] - If provided, an identifier associated with the tool call
 */
type ToolCall = {
    name: string;
    args: Record<string, any>;
    id?: string;
    type?: "tool_call";
};

type IterableReadableStreamInterface<T> = ReadableStream<T> & AsyncIterable<T>;

type RunnableBatchOptions = {
    /** @deprecated Pass in via the standard runnable config object instead */
    maxConcurrency?: number;
    returnExceptions?: boolean;
};
type RunnableIOSchema = {
    name?: string;
    schema: InteropZodType;
};
/**
 * Base interface implemented by all runnables.
 * Used for cross-compatibility between different versions of LangChain core.
 *
 * Should not change on patch releases.
 */
interface RunnableInterface<RunInput = any, RunOutput = any, CallOptions extends RunnableConfig = RunnableConfig> extends SerializableInterface {
    lc_serializable: boolean;
    invoke(input: RunInput, options?: Partial<CallOptions>): Promise<RunOutput>;
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions & {
        returnExceptions?: false;
    }): Promise<RunOutput[]>;
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions & {
        returnExceptions: true;
    }): Promise<(RunOutput | Error)[]>;
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions): Promise<(RunOutput | Error)[]>;
    stream(input: RunInput, options?: Partial<CallOptions>): Promise<IterableReadableStreamInterface<RunOutput>>;
    transform(generator: AsyncGenerator<RunInput>, options: Partial<CallOptions>): AsyncGenerator<RunOutput>;
    getName(suffix?: string): string;
}
interface Edge {
    source: string;
    target: string;
    data?: string;
    conditional?: boolean;
}
interface Node {
    id: string;
    name: string;
    data: RunnableIOSchema | RunnableInterface;
    metadata?: Record<string, any>;
}
interface RunnableConfig<ConfigurableFieldType extends Record<string, any> = Record<string, any>> extends BaseCallbackConfig {
    /**
     * Runtime values for attributes previously made configurable on this Runnable,
     * or sub-Runnables.
     */
    configurable?: ConfigurableFieldType;
    /**
     * Maximum number of times a call can recurse. If not provided, defaults to 25.
     */
    recursionLimit?: number;
    /** Maximum number of parallel calls to make. */
    maxConcurrency?: number;
    /**
     * Timeout for this call in milliseconds.
     */
    timeout?: number;
    /**
     * Abort signal for this call.
     * If provided, the call will be aborted when the signal is aborted.
     * @see https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal
     */
    signal?: AbortSignal;
}

type Operation = AddOperation<any> | RemoveOperation | ReplaceOperation<any> | MoveOperation | CopyOperation | TestOperation<any> | GetOperation<any>;
interface BaseOperation {
    path: string;
}
interface AddOperation<T> extends BaseOperation {
    op: "add";
    value: T;
}
interface RemoveOperation extends BaseOperation {
    op: "remove";
}
interface ReplaceOperation<T> extends BaseOperation {
    op: "replace";
    value: T;
}
interface MoveOperation extends BaseOperation {
    op: "move";
    from: string;
}
interface CopyOperation extends BaseOperation {
    op: "copy";
    from: string;
}
interface TestOperation<T> extends BaseOperation {
    op: "test";
    value: T;
}
interface GetOperation<T> extends BaseOperation {
    op: "_get";
    value: T;
}

declare class IterableReadableStream<T> extends ReadableStream<T> implements IterableReadableStreamInterface<T> {
    reader: ReadableStreamDefaultReader<T>;
    ensureReader(): void;
    next(): Promise<IteratorResult<T>>;
    return(): Promise<IteratorResult<T>>;
    throw(e: any): Promise<IteratorResult<T>>;
    [Symbol.asyncIterator](): this;
    [Symbol.asyncDispose](): Promise<void>;
    static fromReadableStream<T>(stream: ReadableStream<T>): IterableReadableStream<T>;
    static fromAsyncGenerator<T>(generator: AsyncGenerator<T>): IterableReadableStream<T>;
}

/**
 * Data associated with a StreamEvent.
 */
type StreamEventData = {
    /**
     * The input passed to the runnable that generated the event.
     * Inputs will sometimes be available at the *START* of the runnable, and
     * sometimes at the *END* of the runnable.
     * If a runnable is able to stream its inputs, then its input by definition
     * won't be known until the *END* of the runnable when it has finished streaming
     * its inputs.
     */
    input?: any;
    /**
     * The output of the runnable that generated the event.
     * Outputs will only be available at the *END* of the runnable.
     * For most runnables, this field can be inferred from the `chunk` field,
     * though there might be some exceptions for special cased runnables (e.g., like
     * chat models), which may return more information.
     */
    output?: any;
    /**
     * A streaming chunk from the output that generated the event.
     * chunks support addition in general, and adding them up should result
     * in the output of the runnable that generated the event.
     */
    chunk?: any;
};
/**
 * A streaming event.
 *
 * Schema of a streaming event which is produced from the streamEvents method.
 */
type StreamEvent = {
    /**
     * Event names are of the format: on_[runnable_type]_(start|stream|end).
     *
     * Runnable types are one of:
     * - llm - used by non chat models
     * - chat_model - used by chat models
     * - prompt --  e.g., ChatPromptTemplate
     * - tool -- LangChain tools
     * - chain - most Runnables are of this type
     *
     * Further, the events are categorized as one of:
     * - start - when the runnable starts
     * - stream - when the runnable is streaming
     * - end - when the runnable ends
     *
     * start, stream and end are associated with slightly different `data` payload.
     *
     * Please see the documentation for `EventData` for more details.
     */
    event: string;
    /** The name of the runnable that generated the event. */
    name: string;
    /**
     * An randomly generated ID to keep track of the execution of the given runnable.
     *
     * Each child runnable that gets invoked as part of the execution of a parent runnable
     * is assigned its own unique ID.
     */
    run_id: string;
    /**
     * Tags associated with the runnable that generated this event.
     * Tags are always inherited from parent runnables.
     */
    tags?: string[];
    /** Metadata associated with the runnable that generated this event. */
    metadata: Record<string, any>;
    /**
     * Event data.
     *
     * The contents of the event data depend on the event type.
     */
    data: StreamEventData;
};
interface EventStreamCallbackHandlerInput extends BaseCallbackHandlerInput {
    autoClose?: boolean;
    includeNames?: string[];
    includeTypes?: string[];
    includeTags?: string[];
    excludeNames?: string[];
    excludeTypes?: string[];
    excludeTags?: string[];
}

/**
 * Interface that represents the structure of a log entry in the
 * `LogStreamCallbackHandler`.
 */
type LogEntry = {
    /** ID of the sub-run. */
    id: string;
    /** Name of the object being run. */
    name: string;
    /** Type of the object being run, eg. prompt, chain, llm, etc. */
    type: string;
    /** List of tags for the run. */
    tags: string[];
    /** Key-value pairs of metadata for the run. */
    metadata: Record<string, any>;
    /** ISO-8601 timestamp of when the run started. */
    start_time: string;
    /** List of general output chunks streamed by this run. */
    streamed_output: any[];
    /** List of LLM tokens streamed by this run, if applicable. */
    streamed_output_str: string[];
    /** Inputs to this run. Not available currently via streamLog. */
    inputs?: any;
    /** Final output of this run. Only available after the run has finished successfully. */
    final_output?: any;
    /** ISO-8601 timestamp of when the run ended. Only available after the run has finished. */
    end_time?: string;
};
type RunState = {
    /** ID of the sub-run. */
    id: string;
    /** List of output chunks streamed by Runnable.stream() */
    streamed_output: any[];
    /** Final output of the run, usually the result of aggregating streamed_output. Only available after the run has finished successfully. */
    final_output?: any;
    /**
     * List of sub-runs contained in this run, if any, in the order they were started.
     * If filters were supplied, this list will contain only the runs that matched the filters.
     */
    logs: Record<string, LogEntry>;
    /** Name of the object being run. */
    name: string;
    /** Type of the object being run, eg. prompt, chain, llm, etc. */
    type: string;
};
/**
 * List of jsonpatch JSONPatchOperations, which describe how to create the run state
 * from an empty dict. This is the minimal representation of the log, designed to
 * be serialized as JSON and sent over the wire to reconstruct the log on the other
 * side. Reconstruction of the state can be done with any jsonpatch-compliant library,
 * see https://jsonpatch.com for more information.
 */
declare class RunLogPatch {
    ops: Operation[];
    constructor(fields: {
        ops?: Operation[];
    });
    concat(other: RunLogPatch): RunLog;
}
declare class RunLog extends RunLogPatch {
    state: RunState;
    constructor(fields: {
        ops?: Operation[];
        state: RunState;
    });
    concat(other: RunLogPatch): RunLog;
    static fromRunLogPatch(patch: RunLogPatch): RunLog;
}
type SchemaFormat = "original" | "streaming_events";
interface LogStreamCallbackHandlerInput extends BaseCallbackHandlerInput {
    autoClose?: boolean;
    includeNames?: string[];
    includeTypes?: string[];
    includeTags?: string[];
    excludeNames?: string[];
    excludeTypes?: string[];
    excludeTags?: string[];
    _schemaFormat?: SchemaFormat;
}
/**
 * Class that extends the `BaseTracer` class from the
 * `langchain.callbacks.tracers.base` module. It represents a callback
 * handler that logs the execution of runs and emits `RunLog` instances to a
 * `RunLogStream`.
 */
declare class LogStreamCallbackHandler extends BaseTracer implements CallbackHandlerPrefersStreaming {
    protected autoClose: boolean;
    protected includeNames?: string[];
    protected includeTypes?: string[];
    protected includeTags?: string[];
    protected excludeNames?: string[];
    protected excludeTypes?: string[];
    protected excludeTags?: string[];
    protected _schemaFormat: SchemaFormat;
    protected rootId?: string;
    private keyMapByRunId;
    private counterMapByRunName;
    protected transformStream: TransformStream;
    writer: WritableStreamDefaultWriter;
    receiveStream: IterableReadableStream<RunLogPatch>;
    name: string;
    lc_prefer_streaming: boolean;
    constructor(fields?: LogStreamCallbackHandlerInput);
    [Symbol.asyncIterator](): IterableReadableStream<RunLogPatch>;
    protected persistRun(_run: Run): Promise<void>;
    _includeRun(run: Run): boolean;
    tapOutputIterable<T>(runId: string, output: AsyncGenerator<T>): AsyncGenerator<T>;
    onRunCreate(run: Run): Promise<void>;
    onRunUpdate(run: Run): Promise<void>;
    onLLMNewToken(run: Run, token: string, kwargs?: HandleLLMNewTokenCallbackFields): Promise<void>;
}

declare class Graph {
    nodes: Record<string, Node>;
    edges: Edge[];
    constructor(params?: {
        nodes: Record<string, Node>;
        edges: Edge[];
    });
    toJSON(): Record<string, any>;
    addNode(data: RunnableInterface | RunnableIOSchema, id?: string, metadata?: Record<string, any>): Node;
    removeNode(node: Node): void;
    addEdge(source: Node, target: Node, data?: string, conditional?: boolean): Edge;
    firstNode(): Node | undefined;
    lastNode(): Node | undefined;
    /**
     * Add all nodes and edges from another graph.
     * Note this doesn't check for duplicates, nor does it connect the graphs.
     */
    extend(graph: Graph, prefix?: string): ({
        id: string;
        data: RunnableIOSchema | RunnableInterface<any, any, RunnableConfig<Record<string, any>>>;
    } | undefined)[];
    trimFirstNode(): void;
    trimLastNode(): void;
    /**
     * Return a new graph with all nodes re-identified,
     * using their unique, readable names where possible.
     */
    reid(): Graph;
    drawMermaid(params?: {
        withStyles?: boolean;
        curveStyle?: string;
        nodeColors?: Record<string, string>;
        wrapLabelNWords?: number;
    }): string;
    drawMermaidPng(params?: {
        withStyles?: boolean;
        curveStyle?: string;
        nodeColors?: Record<string, string>;
        wrapLabelNWords?: number;
        backgroundColor?: string;
    }): Promise<Blob>;
}

type RunnableFunc<RunInput, RunOutput, CallOptions extends RunnableConfig = RunnableConfig> = (input: RunInput, options: CallOptions | Record<string, any> | (Record<string, any> & CallOptions)) => RunOutput | Promise<RunOutput>;
type RunnableMapLike<RunInput, RunOutput> = {
    [K in keyof RunOutput]: RunnableLike<RunInput, RunOutput[K]>;
};
type RunnableLike<RunInput = any, RunOutput = any, CallOptions extends RunnableConfig = RunnableConfig> = RunnableInterface<RunInput, RunOutput, CallOptions> | RunnableFunc<RunInput, RunOutput, CallOptions> | RunnableMapLike<RunInput, RunOutput>;
type RunnableRetryFailedAttemptHandler = (error: any, input: any) => any;
/**
 * A Runnable is a generic unit of work that can be invoked, batched, streamed, and/or
 * transformed.
 */
declare abstract class Runnable<RunInput = any, RunOutput = any, CallOptions extends RunnableConfig = RunnableConfig> extends Serializable implements RunnableInterface<RunInput, RunOutput, CallOptions> {
    protected lc_runnable: boolean;
    name?: string;
    getName(suffix?: string): string;
    abstract invoke(input: RunInput, options?: Partial<CallOptions>): Promise<RunOutput>;
    /**
     * Bind arguments to a Runnable, returning a new Runnable.
     * @param kwargs
     * @returns A new RunnableBinding that, when invoked, will apply the bound args.
     *
     * @deprecated Use {@link withConfig} instead. This will be removed in the next breaking release.
     */
    bind(kwargs: Partial<CallOptions>): Runnable<RunInput, RunOutput, CallOptions>;
    /**
     * Return a new Runnable that maps a list of inputs to a list of outputs,
     * by calling invoke() with each input.
     *
     * @deprecated This will be removed in the next breaking release.
     */
    map(): Runnable<RunInput[], RunOutput[], CallOptions>;
    /**
     * Add retry logic to an existing runnable.
     * @param fields.stopAfterAttempt The number of attempts to retry.
     * @param fields.onFailedAttempt A function that is called when a retry fails.
     * @returns A new RunnableRetry that, when invoked, will retry according to the parameters.
     */
    withRetry(fields?: {
        stopAfterAttempt?: number;
        onFailedAttempt?: RunnableRetryFailedAttemptHandler;
    }): RunnableRetry<RunInput, RunOutput, CallOptions>;
    /**
     * Bind config to a Runnable, returning a new Runnable.
     * @param config New configuration parameters to attach to the new runnable.
     * @returns A new RunnableBinding with a config matching what's passed.
     */
    withConfig(config: Partial<CallOptions>): Runnable<RunInput, RunOutput, CallOptions>;
    /**
     * Create a new runnable from the current one that will try invoking
     * other passed fallback runnables if the initial invocation fails.
     * @param fields.fallbacks Other runnables to call if the runnable errors.
     * @returns A new RunnableWithFallbacks.
     */
    withFallbacks(fields: {
        fallbacks: Runnable<RunInput, RunOutput>[];
    } | Runnable<RunInput, RunOutput>[]): RunnableWithFallbacks<RunInput, RunOutput>;
    protected _getOptionsList<O extends CallOptions & {
        runType?: string;
    }>(options: Partial<O> | Partial<O>[], length?: number): Partial<O>[];
    /**
     * Default implementation of batch, which calls invoke N times.
     * Subclasses should override this method if they can batch more efficiently.
     * @param inputs Array of inputs to each batch call.
     * @param options Either a single call options object to apply to each batch call or an array for each call.
     * @param batchOptions.returnExceptions Whether to return errors rather than throwing on the first one
     * @returns An array of RunOutputs, or mixed RunOutputs and errors if batchOptions.returnExceptions is set
     */
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions & {
        returnExceptions?: false;
    }): Promise<RunOutput[]>;
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions & {
        returnExceptions: true;
    }): Promise<(RunOutput | Error)[]>;
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions): Promise<(RunOutput | Error)[]>;
    /**
     * Default streaming implementation.
     * Subclasses should override this method if they support streaming output.
     * @param input
     * @param options
     */
    _streamIterator(input: RunInput, options?: Partial<CallOptions>): AsyncGenerator<RunOutput>;
    /**
     * Stream output in chunks.
     * @param input
     * @param options
     * @returns A readable stream that is also an iterable.
     */
    stream(input: RunInput, options?: Partial<CallOptions>): Promise<IterableReadableStream<RunOutput>>;
    protected _separateRunnableConfigFromCallOptions(options?: Partial<CallOptions>): [RunnableConfig, Omit<Partial<CallOptions>, keyof RunnableConfig>];
    protected _callWithConfig<T extends RunInput>(func: ((input: T) => Promise<RunOutput>) | ((input: T, config?: Partial<CallOptions>, runManager?: CallbackManagerForChainRun) => Promise<RunOutput>), input: T, options?: Partial<CallOptions> & {
        runType?: string;
    }): Promise<RunOutput>;
    /**
     * Internal method that handles batching and configuration for a runnable
     * It takes a function, input values, and optional configuration, and
     * returns a promise that resolves to the output values.
     * @param func The function to be executed for each input value.
     * @param input The input values to be processed.
     * @param config Optional configuration for the function execution.
     * @returns A promise that resolves to the output values.
     */
    _batchWithConfig<T extends RunInput>(func: (inputs: T[], options?: Partial<CallOptions>[], runManagers?: (CallbackManagerForChainRun | undefined)[], batchOptions?: RunnableBatchOptions) => Promise<(RunOutput | Error)[]>, inputs: T[], options?: Partial<CallOptions & {
        runType?: string;
    }> | Partial<CallOptions & {
        runType?: string;
    }>[], batchOptions?: RunnableBatchOptions): Promise<(RunOutput | Error)[]>;
    /**
     * Helper method to transform an Iterator of Input values into an Iterator of
     * Output values, with callbacks.
     * Use this to implement `stream()` or `transform()` in Runnable subclasses.
     */
    protected _transformStreamWithConfig<I extends RunInput, O extends RunOutput>(inputGenerator: AsyncGenerator<I>, transformer: (generator: AsyncGenerator<I>, runManager?: CallbackManagerForChainRun, options?: Partial<CallOptions>) => AsyncGenerator<O>, options?: Partial<CallOptions> & {
        runType?: string;
    }): AsyncGenerator<O>;
    getGraph(_?: RunnableConfig): Graph;
    /**
     * Create a new runnable sequence that runs each individual runnable in series,
     * piping the output of one runnable into another runnable or runnable-like.
     * @param coerceable A runnable, function, or object whose values are functions or runnables.
     * @returns A new runnable sequence.
     */
    pipe<NewRunOutput>(coerceable: RunnableLike<RunOutput, NewRunOutput>): Runnable<RunInput, Exclude<NewRunOutput, Error>>;
    /**
     * Pick keys from the dict output of this runnable. Returns a new runnable.
     */
    pick(keys: string | string[]): Runnable;
    /**
     * Assigns new fields to the dict output of this runnable. Returns a new runnable.
     */
    assign(mapping: RunnableMapLike<Record<string, unknown>, Record<string, unknown>>): Runnable;
    /**
     * Default implementation of transform, which buffers input and then calls stream.
     * Subclasses should override this method if they can start producing output while
     * input is still being generated.
     * @param generator
     * @param options
     */
    transform(generator: AsyncGenerator<RunInput>, options: Partial<CallOptions>): AsyncGenerator<RunOutput>;
    /**
     * Stream all output from a runnable, as reported to the callback system.
     * This includes all inner runs of LLMs, Retrievers, Tools, etc.
     * Output is streamed as Log objects, which include a list of
     * jsonpatch ops that describe how the state of the run has changed in each
     * step, and the final state of the run.
     * The jsonpatch ops can be applied in order to construct state.
     * @param input
     * @param options
     * @param streamOptions
     */
    streamLog(input: RunInput, options?: Partial<CallOptions>, streamOptions?: Omit<LogStreamCallbackHandlerInput, "autoClose">): AsyncGenerator<RunLogPatch>;
    protected _streamLog(input: RunInput, logStreamCallbackHandler: LogStreamCallbackHandler, config: Partial<CallOptions>): AsyncGenerator<RunLogPatch>;
    /**
     * Generate a stream of events emitted by the internal steps of the runnable.
     *
     * Use to create an iterator over StreamEvents that provide real-time information
     * about the progress of the runnable, including StreamEvents from intermediate
     * results.
     *
     * A StreamEvent is a dictionary with the following schema:
     *
     * - `event`: string - Event names are of the format: on_[runnable_type]_(start|stream|end).
     * - `name`: string - The name of the runnable that generated the event.
     * - `run_id`: string - Randomly generated ID associated with the given execution of
     *   the runnable that emitted the event. A child runnable that gets invoked as part of the execution of a
     *   parent runnable is assigned its own unique ID.
     * - `tags`: string[] - The tags of the runnable that generated the event.
     * - `metadata`: Record<string, any> - The metadata of the runnable that generated the event.
     * - `data`: Record<string, any>
     *
     * Below is a table that illustrates some events that might be emitted by various
     * chains. Metadata fields have been omitted from the table for brevity.
     * Chain definitions have been included after the table.
     *
     * **ATTENTION** This reference table is for the V2 version of the schema.
     *
     * ```md
     * +----------------------+-----------------------------+------------------------------------------+
     * | event                | input                       | output/chunk                             |
     * +======================+=============================+==========================================+
     * | on_chat_model_start  | {"messages": BaseMessage[]} |                                          |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_chat_model_stream |                             | AIMessageChunk("hello")                  |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_chat_model_end    | {"messages": BaseMessage[]} | AIMessageChunk("hello world")            |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_llm_start         | {'input': 'hello'}          |                                          |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_llm_stream        |                             | 'Hello'                                  |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_llm_end           | 'Hello human!'              |                                          |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_chain_start       |                             |                                          |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_chain_stream      |                             | "hello world!"                           |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_chain_end         | [Document(...)]             | "hello world!, goodbye world!"           |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_tool_start        | {"x": 1, "y": "2"}          |                                          |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_tool_end          |                             | {"x": 1, "y": "2"}                       |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_retriever_start   | {"query": "hello"}          |                                          |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_retriever_end     | {"query": "hello"}          | [Document(...), ..]                      |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_prompt_start      | {"question": "hello"}       |                                          |
     * +----------------------+-----------------------------+------------------------------------------+
     * | on_prompt_end        | {"question": "hello"}       | ChatPromptValue(messages: BaseMessage[]) |
     * +----------------------+-----------------------------+------------------------------------------+
     * ```
     *
     * The "on_chain_*" events are the default for Runnables that don't fit one of the above categories.
     *
     * In addition to the standard events above, users can also dispatch custom events.
     *
     * Custom events will be only be surfaced with in the `v2` version of the API!
     *
     * A custom event has following format:
     *
     * ```md
     * +-----------+------+------------------------------------------------------------+
     * | Attribute | Type | Description                                                |
     * +===========+======+============================================================+
     * | name      | str  | A user defined name for the event.                         |
     * +-----------+------+------------------------------------------------------------+
     * | data      | Any  | The data associated with the event. This can be anything.  |
     * +-----------+------+------------------------------------------------------------+
     * ```
     *
     * Here's an example:
     *
     * ```ts
     * import { RunnableLambda } from "@langchain/core/runnables";
     * import { dispatchCustomEvent } from "@langchain/core/callbacks/dispatch";
     * // Use this import for web environments that don't support "async_hooks"
     * // and manually pass config to child runs.
     * // import { dispatchCustomEvent } from "@langchain/core/callbacks/dispatch/web";
     *
     * const slowThing = RunnableLambda.from(async (someInput: string) => {
     *   // Placeholder for some slow operation
     *   await new Promise((resolve) => setTimeout(resolve, 100));
     *   await dispatchCustomEvent("progress_event", {
     *    message: "Finished step 1 of 2",
     *  });
     *  await new Promise((resolve) => setTimeout(resolve, 100));
     *  return "Done";
     * });
     *
     * const eventStream = await slowThing.streamEvents("hello world", {
     *   version: "v2",
     * });
     *
     * for await (const event of eventStream) {
     *  if (event.event === "on_custom_event") {
     *    console.log(event);
     *  }
     * }
     * ```
     */
    streamEvents(input: RunInput, options: Partial<CallOptions> & {
        version: "v1" | "v2";
    }, streamOptions?: Omit<EventStreamCallbackHandlerInput, "autoClose">): IterableReadableStream<StreamEvent>;
    streamEvents(input: RunInput, options: Partial<CallOptions> & {
        version: "v1" | "v2";
        encoding: "text/event-stream";
    }, streamOptions?: Omit<EventStreamCallbackHandlerInput, "autoClose">): IterableReadableStream<Uint8Array>;
    private _streamEventsV2;
    private _streamEventsV1;
    static isRunnable(thing: any): thing is Runnable;
    /**
     * Bind lifecycle listeners to a Runnable, returning a new Runnable.
     * The Run object contains information about the run, including its id,
     * type, input, output, error, startTime, endTime, and any tags or metadata
     * added to the run.
     *
     * @param {Object} params - The object containing the callback functions.
     * @param {(run: Run) => void} params.onStart - Called before the runnable starts running, with the Run object.
     * @param {(run: Run) => void} params.onEnd - Called after the runnable finishes running, with the Run object.
     * @param {(run: Run) => void} params.onError - Called if the runnable throws an error, with the Run object.
     */
    withListeners({ onStart, onEnd, onError, }: {
        onStart?: (run: Run, config?: RunnableConfig) => void | Promise<void>;
        onEnd?: (run: Run, config?: RunnableConfig) => void | Promise<void>;
        onError?: (run: Run, config?: RunnableConfig) => void | Promise<void>;
    }): Runnable<RunInput, RunOutput, CallOptions>;
    /**
     * Convert a runnable to a tool. Return a new instance of `RunnableToolLike`
     * which contains the runnable, name, description and schema.
     *
     * @template {T extends RunInput = RunInput} RunInput - The input type of the runnable. Should be the same as the `RunInput` type of the runnable.
     *
     * @param fields
     * @param {string | undefined} [fields.name] The name of the tool. If not provided, it will default to the name of the runnable.
     * @param {string | undefined} [fields.description] The description of the tool. Falls back to the description on the Zod schema if not provided, or undefined if neither are provided.
     * @param {z.ZodType<T>} [fields.schema] The Zod schema for the input of the tool. Infers the Zod type from the input type of the runnable.
     * @returns {RunnableToolLike<z.ZodType<T>, RunOutput>} An instance of `RunnableToolLike` which is a runnable that can be used as a tool.
     */
    asTool<T extends RunInput = RunInput>(fields: {
        name?: string;
        description?: string;
        schema: InteropZodType<T>;
    }): RunnableToolLike<InteropZodType<T | ToolCall>, RunOutput>;
}
type RunnableBindingArgs<RunInput, RunOutput, CallOptions extends RunnableConfig = RunnableConfig> = {
    bound: Runnable<RunInput, RunOutput, CallOptions>;
    /**
     * @deprecated use {@link config} instead
     */
    kwargs?: Partial<CallOptions>;
    config: RunnableConfig;
    configFactories?: Array<(config: RunnableConfig) => RunnableConfig | Promise<RunnableConfig>>;
};
/**
 * Wraps a runnable and applies partial config upon invocation.
 *
 * @example
 * ```typescript
 * import {
 *   type RunnableConfig,
 *   RunnableLambda,
 * } from "@langchain/core/runnables";
 *
 * const enhanceProfile = (
 *   profile: Record<string, any>,
 *   config?: RunnableConfig
 * ) => {
 *   if (config?.configurable?.role) {
 *     return { ...profile, role: config.configurable.role };
 *   }
 *   return profile;
 * };
 *
 * const runnable = RunnableLambda.from(enhanceProfile);
 *
 * // Bind configuration to the runnable to set the user's role dynamically
 * const adminRunnable = runnable.bind({ configurable: { role: "Admin" } });
 * const userRunnable = runnable.bind({ configurable: { role: "User" } });
 *
 * const result1 = await adminRunnable.invoke({
 *   name: "Alice",
 *   email: "alice@example.com"
 * });
 *
 * // { name: "Alice", email: "alice@example.com", role: "Admin" }
 *
 * const result2 = await userRunnable.invoke({
 *   name: "Bob",
 *   email: "bob@example.com"
 * });
 *
 * // { name: "Bob", email: "bob@example.com", role: "User" }
 * ```
 */
declare class RunnableBinding<RunInput, RunOutput, CallOptions extends RunnableConfig = RunnableConfig> extends Runnable<RunInput, RunOutput, CallOptions> {
    static lc_name(): string;
    lc_namespace: string[];
    lc_serializable: boolean;
    bound: Runnable<RunInput, RunOutput, CallOptions>;
    config: RunnableConfig;
    kwargs?: Partial<CallOptions>;
    configFactories?: Array<(config: RunnableConfig) => RunnableConfig | Promise<RunnableConfig>>;
    constructor(fields: RunnableBindingArgs<RunInput, RunOutput, CallOptions>);
    getName(suffix?: string | undefined): string;
    _mergeConfig(...options: (Partial<CallOptions> | RunnableConfig | undefined)[]): Promise<Partial<CallOptions>>;
    /**
     * Binds the runnable with the specified arguments.
     * @param kwargs The arguments to bind the runnable with.
     * @returns A new instance of the `RunnableBinding` class that is bound with the specified arguments.
     *
     * @deprecated Use {@link withConfig} instead. This will be removed in the next breaking release.
     */
    bind(kwargs: Partial<CallOptions>): RunnableBinding<RunInput, RunOutput, CallOptions>;
    withConfig(config: Partial<CallOptions>): Runnable<RunInput, RunOutput, CallOptions>;
    withRetry(fields?: {
        stopAfterAttempt?: number;
        onFailedAttempt?: RunnableRetryFailedAttemptHandler;
    }): RunnableRetry<RunInput, RunOutput, CallOptions>;
    invoke(input: RunInput, options?: Partial<CallOptions>): Promise<RunOutput>;
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions & {
        returnExceptions?: false;
    }): Promise<RunOutput[]>;
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions & {
        returnExceptions: true;
    }): Promise<(RunOutput | Error)[]>;
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions): Promise<(RunOutput | Error)[]>;
    _streamIterator(input: RunInput, options?: Partial<CallOptions> | undefined): AsyncGenerator<Awaited<RunOutput>, void, any>;
    stream(input: RunInput, options?: Partial<CallOptions> | undefined): Promise<IterableReadableStream<RunOutput>>;
    transform(generator: AsyncGenerator<RunInput>, options?: Partial<CallOptions>): AsyncGenerator<RunOutput>;
    streamEvents(input: RunInput, options: Partial<CallOptions> & {
        version: "v1" | "v2";
    }, streamOptions?: Omit<LogStreamCallbackHandlerInput, "autoClose">): IterableReadableStream<StreamEvent>;
    streamEvents(input: RunInput, options: Partial<CallOptions> & {
        version: "v1" | "v2";
        encoding: "text/event-stream";
    }, streamOptions?: Omit<LogStreamCallbackHandlerInput, "autoClose">): IterableReadableStream<Uint8Array>;
    static isRunnableBinding(thing: any): thing is RunnableBinding<any, any, any>;
    /**
     * Bind lifecycle listeners to a Runnable, returning a new Runnable.
     * The Run object contains information about the run, including its id,
     * type, input, output, error, startTime, endTime, and any tags or metadata
     * added to the run.
     *
     * @param {Object} params - The object containing the callback functions.
     * @param {(run: Run) => void} params.onStart - Called before the runnable starts running, with the Run object.
     * @param {(run: Run) => void} params.onEnd - Called after the runnable finishes running, with the Run object.
     * @param {(run: Run) => void} params.onError - Called if the runnable throws an error, with the Run object.
     */
    withListeners({ onStart, onEnd, onError, }: {
        onStart?: (run: Run, config?: RunnableConfig) => void | Promise<void>;
        onEnd?: (run: Run, config?: RunnableConfig) => void | Promise<void>;
        onError?: (run: Run, config?: RunnableConfig) => void | Promise<void>;
    }): Runnable<RunInput, RunOutput, CallOptions>;
}
/**
 * Base class for runnables that can be retried a
 * specified number of times.
 * @example
 * ```typescript
 * import {
 *   RunnableLambda,
 *   RunnableRetry,
 * } from "@langchain/core/runnables";
 *
 * // Simulate an API call that fails
 * const simulateApiCall = (input: string): string => {
 *   console.log(`Attempting API call with input: ${input}`);
 *   throw new Error("API call failed due to network issue");
 * };
 *
 * const apiCallLambda = RunnableLambda.from(simulateApiCall);
 *
 * // Apply retry logic using the .withRetry() method
 * const apiCallWithRetry = apiCallLambda.withRetry({ stopAfterAttempt: 3 });
 *
 * // Alternatively, create a RunnableRetry instance manually
 * const manualRetry = new RunnableRetry({
 *   bound: apiCallLambda,
 *   maxAttemptNumber: 3,
 *   config: {},
 * });
 *
 * // Example invocation using the .withRetry() method
 * const res = await apiCallWithRetry
 *   .invoke("Request 1")
 *   .catch((error) => {
 *     console.error("Failed after multiple retries:", error.message);
 *   });
 *
 * // Example invocation using the manual retry instance
 * const res2 = await manualRetry
 *   .invoke("Request 2")
 *   .catch((error) => {
 *     console.error("Failed after multiple retries:", error.message);
 *   });
 * ```
 */
declare class RunnableRetry<RunInput = any, RunOutput = any, CallOptions extends RunnableConfig = RunnableConfig> extends RunnableBinding<RunInput, RunOutput, CallOptions> {
    static lc_name(): string;
    lc_namespace: string[];
    protected maxAttemptNumber: number;
    onFailedAttempt: RunnableRetryFailedAttemptHandler;
    constructor(fields: RunnableBindingArgs<RunInput, RunOutput, CallOptions> & {
        maxAttemptNumber?: number;
        onFailedAttempt?: RunnableRetryFailedAttemptHandler;
    });
    _patchConfigForRetry(attempt: number, config?: Partial<CallOptions>, runManager?: CallbackManagerForChainRun): Partial<CallOptions>;
    protected _invoke(input: RunInput, config?: CallOptions, runManager?: CallbackManagerForChainRun): Promise<RunOutput>;
    /**
     * Method that invokes the runnable with the specified input, run manager,
     * and config. It handles the retry logic by catching any errors and
     * recursively invoking itself with the updated config for the next retry
     * attempt.
     * @param input The input for the runnable.
     * @param runManager The run manager for the runnable.
     * @param config The config for the runnable.
     * @returns A promise that resolves to the output of the runnable.
     */
    invoke(input: RunInput, config?: CallOptions): Promise<RunOutput>;
    _batch<ReturnExceptions extends boolean = false>(inputs: RunInput[], configs?: RunnableConfig[], runManagers?: (CallbackManagerForChainRun | undefined)[], batchOptions?: RunnableBatchOptions): Promise<ReturnExceptions extends false ? RunOutput[] : (Error | RunOutput)[]>;
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions & {
        returnExceptions?: false;
    }): Promise<RunOutput[]>;
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions & {
        returnExceptions: true;
    }): Promise<(RunOutput | Error)[]>;
    batch(inputs: RunInput[], options?: Partial<CallOptions> | Partial<CallOptions>[], batchOptions?: RunnableBatchOptions): Promise<(RunOutput | Error)[]>;
}
/**
 * A Runnable that can fallback to other Runnables if it fails.
 * External APIs (e.g., APIs for a language model) may at times experience
 * degraded performance or even downtime.
 *
 * In these cases, it can be useful to have a fallback Runnable that can be
 * used in place of the original Runnable (e.g., fallback to another LLM provider).
 *
 * Fallbacks can be defined at the level of a single Runnable, or at the level
 * of a chain of Runnables. Fallbacks are tried in order until one succeeds or
 * all fail.
 *
 * While you can instantiate a `RunnableWithFallbacks` directly, it is usually
 * more convenient to use the `withFallbacks` method on an existing Runnable.
 *
 * When streaming, fallbacks will only be called on failures during the initial
 * stream creation. Errors that occur after a stream starts will not fallback
 * to the next Runnable.
 *
 * @example
 * ```typescript
 * import {
 *   RunnableLambda,
 *   RunnableWithFallbacks,
 * } from "@langchain/core/runnables";
 *
 * const primaryOperation = (input: string): string => {
 *   if (input !== "safe") {
 *     throw new Error("Primary operation failed due to unsafe input");
 *   }
 *   return `Processed: ${input}`;
 * };
 *
 * // Define a fallback operation that processes the input differently
 * const fallbackOperation = (input: string): string =>
 *   `Fallback processed: ${input}`;
 *
 * const primaryRunnable = RunnableLambda.from(primaryOperation);
 * const fallbackRunnable = RunnableLambda.from(fallbackOperation);
 *
 * // Apply the fallback logic using the .withFallbacks() method
 * const runnableWithFallback = primaryRunnable.withFallbacks([fallbackRunnable]);
 *
 * // Alternatively, create a RunnableWithFallbacks instance manually
 * const manualFallbackChain = new RunnableWithFallbacks({
 *   runnable: primaryRunnable,
 *   fallbacks: [fallbackRunnable],
 * });
 *
 * // Example invocation using .withFallbacks()
 * const res = await runnableWithFallback
 *   .invoke("unsafe input")
 *   .catch((error) => {
 *     console.error("Failed after all attempts:", error.message);
 *   });
 *
 * // "Fallback processed: unsafe input"
 *
 * // Example invocation using manual instantiation
 * const res = await manualFallbackChain
 *   .invoke("safe")
 *   .catch((error) => {
 *     console.error("Failed after all attempts:", error.message);
 *   });
 *
 * // "Processed: safe"
 * ```
 */
declare class RunnableWithFallbacks<RunInput, RunOutput> extends Runnable<RunInput, RunOutput> {
    static lc_name(): string;
    lc_namespace: string[];
    lc_serializable: boolean;
    runnable: Runnable<RunInput, RunOutput>;
    fallbacks: Runnable<RunInput, RunOutput>[];
    constructor(fields: {
        runnable: Runnable<RunInput, RunOutput>;
        fallbacks: Runnable<RunInput, RunOutput>[];
    });
    runnables(): Generator<Runnable<RunInput, RunOutput, RunnableConfig<Record<string, any>>>, void, unknown>;
    invoke(input: RunInput, options?: Partial<RunnableConfig>): Promise<RunOutput>;
    _streamIterator(input: RunInput, options?: Partial<RunnableConfig> | undefined): AsyncGenerator<RunOutput>;
    batch(inputs: RunInput[], options?: Partial<RunnableConfig> | Partial<RunnableConfig>[], batchOptions?: RunnableBatchOptions & {
        returnExceptions?: false;
    }): Promise<RunOutput[]>;
    batch(inputs: RunInput[], options?: Partial<RunnableConfig> | Partial<RunnableConfig>[], batchOptions?: RunnableBatchOptions & {
        returnExceptions: true;
    }): Promise<(RunOutput | Error)[]>;
    batch(inputs: RunInput[], options?: Partial<RunnableConfig> | Partial<RunnableConfig>[], batchOptions?: RunnableBatchOptions): Promise<(RunOutput | Error)[]>;
}
interface RunnableToolLikeArgs<RunInput extends InteropZodType = InteropZodType, RunOutput = unknown> extends Omit<RunnableBindingArgs<InferInteropZodOutput<RunInput>, RunOutput>, "config"> {
    name: string;
    description?: string;
    schema: RunInput;
    config?: RunnableConfig;
}
declare class RunnableToolLike<RunInput extends InteropZodType = InteropZodType, RunOutput = unknown> extends RunnableBinding<InferInteropZodOutput<RunInput>, RunOutput> {
    name: string;
    description?: string;
    schema: RunInput;
    constructor(fields: RunnableToolLikeArgs<RunInput, RunOutput>);
    static lc_name(): string;
}

type JsonSchema7AnyType = {};

type ErrorMessages<T extends JsonSchema7TypeUnion, OmitProperties extends string = ""> = Partial<Omit<{
    [key in keyof T]: string;
}, OmitProperties | "type" | "errorMessages">>;

type JsonSchema7ArrayType = {
    type: "array";
    items?: JsonSchema7Type;
    minItems?: number;
    maxItems?: number;
    errorMessages?: ErrorMessages<JsonSchema7ArrayType, "items">;
};

type JsonSchema7BigintType = {
    type: "integer";
    format: "int64";
    minimum?: BigInt;
    exclusiveMinimum?: BigInt;
    maximum?: BigInt;
    exclusiveMaximum?: BigInt;
    multipleOf?: BigInt;
    errorMessage?: ErrorMessages<JsonSchema7BigintType>;
};

type JsonSchema7BooleanType = {
    type: "boolean";
};

type JsonSchema7NumberType = {
    type: "number" | "integer";
    minimum?: number;
    exclusiveMinimum?: number;
    maximum?: number;
    exclusiveMaximum?: number;
    multipleOf?: number;
    errorMessage?: ErrorMessages<JsonSchema7NumberType>;
};

type JsonSchema7DateType = {
    type: "integer" | "string";
    format: "unix-time" | "date-time" | "date";
    minimum?: number;
    maximum?: number;
    errorMessage?: ErrorMessages<JsonSchema7NumberType>;
} | {
    anyOf: JsonSchema7DateType[];
};

type JsonSchema7EnumType = {
    type: "string";
    enum: string[];
};

type JsonSchema7AllOfType = {
    allOf: JsonSchema7Type[];
    unevaluatedProperties?: boolean;
};

type JsonSchema7LiteralType = {
    type: "string" | "number" | "integer" | "boolean";
    const: string | number | boolean;
} | {
    type: "object" | "array";
};

type JsonSchema7StringType = {
    type: "string";
    minLength?: number;
    maxLength?: number;
    format?: "email" | "idn-email" | "uri" | "uuid" | "date-time" | "ipv4" | "ipv6" | "date" | "time" | "duration";
    pattern?: string;
    allOf?: {
        pattern: string;
        errorMessage?: ErrorMessages<{
            pattern: string;
        }>;
    }[];
    anyOf?: {
        format: string;
        errorMessage?: ErrorMessages<{
            format: string;
        }>;
    }[];
    errorMessage?: ErrorMessages<JsonSchema7StringType>;
    contentEncoding?: string;
};

type JsonSchema7RecordPropertyNamesType = Omit<JsonSchema7StringType, "type"> | Omit<JsonSchema7EnumType, "type">;
type JsonSchema7RecordType = {
    type: "object";
    additionalProperties?: JsonSchema7Type | true;
    propertyNames?: JsonSchema7RecordPropertyNamesType;
};

type JsonSchema7MapType = {
    type: "array";
    maxItems: 125;
    items: {
        type: "array";
        items: [JsonSchema7Type, JsonSchema7Type];
        minItems: 2;
        maxItems: 2;
    };
};

type JsonSchema7NativeEnumType = {
    type: "string" | "number" | ["string", "number"];
    enum: (string | number)[];
};

type JsonSchema7NeverType = {
    not: {};
};

type JsonSchema7NullType = {
    type: "null";
};

type JsonSchema7NullableType = {
    anyOf: [JsonSchema7Type, JsonSchema7NullType];
} | {
    type: [string, "null"];
};

type JsonSchema7ObjectType = {
    type: "object";
    properties: Record<string, JsonSchema7Type>;
    additionalProperties?: boolean | JsonSchema7Type;
    required?: string[];
};

type JsonSchema7SetType = {
    type: "array";
    uniqueItems: true;
    items?: JsonSchema7Type;
    minItems?: number;
    maxItems?: number;
    errorMessage?: ErrorMessages<JsonSchema7SetType>;
};

type JsonSchema7TupleType = {
    type: "array";
    minItems: number;
    items: JsonSchema7Type[];
} & ({
    maxItems: number;
} | {
    additionalItems?: JsonSchema7Type;
});

type JsonSchema7UndefinedType = {
    not: {};
};

declare const primitiveMappings: {
    readonly ZodString: "string";
    readonly ZodNumber: "number";
    readonly ZodBigInt: "integer";
    readonly ZodBoolean: "boolean";
    readonly ZodNull: "null";
};
type JsonSchema7Primitive = (typeof primitiveMappings)[keyof typeof primitiveMappings];
type JsonSchema7UnionType = JsonSchema7PrimitiveUnionType | JsonSchema7AnyOfType;
type JsonSchema7PrimitiveUnionType = {
    type: JsonSchema7Primitive | JsonSchema7Primitive[];
} | {
    type: JsonSchema7Primitive | JsonSchema7Primitive[];
    enum: (string | number | bigint | boolean | null)[];
};
type JsonSchema7AnyOfType = {
    anyOf: JsonSchema7Type[];
};

type JsonSchema7UnknownType = {};

type JsonSchema7RefType = {
    $ref: string;
};
type JsonSchema7Meta = {
    title?: string;
    default?: any;
    description?: string;
    markdownDescription?: string;
};
type JsonSchema7TypeUnion = JsonSchema7StringType | JsonSchema7ArrayType | JsonSchema7NumberType | JsonSchema7BigintType | JsonSchema7BooleanType | JsonSchema7DateType | JsonSchema7EnumType | JsonSchema7LiteralType | JsonSchema7NativeEnumType | JsonSchema7NullType | JsonSchema7NumberType | JsonSchema7ObjectType | JsonSchema7RecordType | JsonSchema7TupleType | JsonSchema7UnionType | JsonSchema7UndefinedType | JsonSchema7RefType | JsonSchema7NeverType | JsonSchema7MapType | JsonSchema7AnyType | JsonSchema7NullableType | JsonSchema7AllOfType | JsonSchema7UnknownType | JsonSchema7SetType;
type JsonSchema7Type = JsonSchema7TypeUnion & JsonSchema7Meta;

type JSONSchema = JsonSchema7Type;

interface BaseLangChainParams {
    verbose?: boolean;
    callbacks?: Callbacks;
    tags?: string[];
    metadata?: Record<string, unknown>;
}
/**
 * Base class for language models, chains, tools.
 */
declare abstract class BaseLangChain<RunInput, RunOutput, CallOptions extends RunnableConfig = RunnableConfig> extends Runnable<RunInput, RunOutput, CallOptions> implements BaseLangChainParams {
    /**
     * Whether to print out response text.
     */
    verbose: boolean;
    callbacks?: Callbacks;
    tags?: string[];
    metadata?: Record<string, unknown>;
    get lc_attributes(): {
        [key: string]: undefined;
    } | undefined;
    constructor(params: BaseLangChainParams);
}

type ResponseFormat = "content" | "content_and_artifact" | string;
type ToolOutputType = any;
/**
 * Conditional type that determines the return type of the {@link StructuredTool.invoke} method.
 * - If the input is a ToolCall, it returns a ToolMessage
 * - If the config is a runnable config and contains a toolCall property, it returns a ToolMessage
 * - Otherwise, it returns the original output type
 */
type ToolReturnType<TInput, TConfig, TOutput> = TOutput extends DirectToolOutput ? TOutput : TConfig extends {
    toolCall: {
        id: string;
    };
} ? ToolMessage : TConfig extends {
    toolCall: {
        id: undefined;
    };
} ? TOutput : TConfig extends {
    toolCall: {
        id?: string;
    };
} ? TOutput | ToolMessage : TInput extends ToolCall ? ToolMessage : TOutput;
/**
 * Base type that establishes the types of input schemas that can be used for LangChain tool
 * definitions.
 */
type ToolInputSchemaBase = z.ZodTypeAny | JSONSchema;
/**
 * Parameters for the Tool classes.
 */
interface ToolParams extends BaseLangChainParams {
    /**
     * The tool response format.
     *
     * If "content" then the output of the tool is interpreted as the contents of a
     * ToolMessage. If "content_and_artifact" then the output is expected to be a
     * two-tuple corresponding to the (content, artifact) of a ToolMessage.
     *
     * @default "content"
     */
    responseFormat?: ResponseFormat;
    /**
     * Default config object for the tool runnable.
     */
    defaultConfig?: ToolRunnableConfig;
    /**
     * Whether to show full details in the thrown parsing errors.
     *
     * @default false
     */
    verboseParsingErrors?: boolean;
}
type ToolRunnableConfig<ConfigurableFieldType extends Record<string, any> = Record<string, any>> = RunnableConfig<ConfigurableFieldType> & {
    toolCall?: ToolCall;
};
/**
 * Utility type that resolves the output type of a tool input schema.
 *
 * Input & Output types are a concept used with Zod schema, as Zod allows for transforms to occur
 * during parsing. When using JSONSchema, input and output types are the same.
 *
 * The input type for a given schema should match the structure of the arguments that the LLM
 * generates as part of its {@link ToolCall}. The output type will be the type that results from
 * applying any transforms defined in your schema. If there are no transforms, the input and output
 * types will be the same.
 */
type ToolInputSchemaOutputType<T> = T extends InteropZodType ? InferInteropZodOutput<T> : T extends JSONSchema ? unknown : never;
/**
 * Utility type that resolves the input type of a tool input schema.
 *
 * Input & Output types are a concept used with Zod schema, as Zod allows for transforms to occur
 * during parsing. When using JSONSchema, input and output types are the same.
 *
 * The input type for a given schema should match the structure of the arguments that the LLM
 * generates as part of its {@link ToolCall}. The output type will be the type that results from
 * applying any transforms defined in your schema. If there are no transforms, the input and output
 * types will be the same.
 */
type ToolInputSchemaInputType<T> = T extends InteropZodType ? InferInteropZodInput<T> : T extends JSONSchema ? unknown : never;
/**
 * Defines the type that will be passed into a tool handler function as a result of a tool call.
 *
 * @param SchemaT - The type of the tool input schema. Usually you don't need to specify this.
 * @param SchemaInputT - The TypeScript type representing the structure of the tool arguments generated by the LLM. Useful for type checking tool handler functions when using JSONSchema.
 */
type StructuredToolCallInput<SchemaT = ToolInputSchemaBase, SchemaInputT = ToolInputSchemaInputType<SchemaT>> = (ToolInputSchemaOutputType<SchemaT> extends string ? string : never) | SchemaInputT | ToolCall;
/**
 * An input schema type for tools that accept a single string input.
 *
 * This schema defines a tool that takes an optional string parameter named "input".
 * It uses Zod's effects to transform the input and strip any extra properties.
 *
 * This is primarily used for creating simple string-based tools where the LLM
 * only needs to provide a single text value as input to the tool.
 */
type StringInputToolSchema = z.ZodType<string | undefined, z.ZodTypeDef, any>;
/**
 * Interface that defines the shape of a LangChain structured tool.
 *
 * A structured tool is a tool that uses a schema to define the structure of the arguments that the
 * LLM generates as part of its {@link ToolCall}.
 *
 * @param SchemaT - The type of the tool input schema. Usually you don't need to specify this.
 * @param SchemaInputT - The TypeScript type representing the structure of the tool arguments generated by the LLM. Useful for type checking tool handler functions when using JSONSchema.
 */
interface StructuredToolInterface<SchemaT = ToolInputSchemaBase, SchemaInputT = ToolInputSchemaInputType<SchemaT>, ToolOutputT = ToolOutputType> extends RunnableInterface<StructuredToolCallInput<SchemaT, SchemaInputT>, ToolOutputT | ToolMessage> {
    lc_namespace: string[];
    /**
     * A Zod schema representing the parameters of the tool.
     */
    schema: SchemaT;
    /**
     * Invokes the tool with the provided argument and configuration.
     * @param arg The input argument for the tool.
     * @param configArg Optional configuration for the tool call.
     * @returns A Promise that resolves with the tool's output.
     */
    invoke<TArg extends StructuredToolCallInput<SchemaT, SchemaInputT>, TConfig extends ToolRunnableConfig | undefined>(arg: TArg, configArg?: TConfig): Promise<ToolReturnType<TArg, TConfig, ToolOutputT>>;
    /**
     * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
     *
     * Calls the tool with the provided argument, configuration, and tags. It
     * parses the input according to the schema, handles any errors, and
     * manages callbacks.
     * @param arg The input argument for the tool.
     * @param configArg Optional configuration or callbacks for the tool.
     * @param tags Optional tags for the tool.
     * @returns A Promise that resolves with a string.
     */
    call<TArg extends StructuredToolCallInput<SchemaT, SchemaInputT>, TConfig extends ToolRunnableConfig | undefined>(arg: TArg, configArg?: TConfig, 
    /** @deprecated */
    tags?: string[]): Promise<ToolReturnType<TArg, TConfig, ToolOutputT>>;
    /**
     * The name of the tool.
     */
    name: string;
    /**
     * A description of the tool.
     */
    description: string;
    /**
     * Whether to return the tool's output directly.
     *
     * Setting this to true means that after the tool is called,
     * an agent should stop looping.
     */
    returnDirect: boolean;
}
/**
 * A special interface for tools that accept a string input, usually defined with the {@link Tool} class.
 *
 * @param SchemaT - The type of the tool input schema. Usually you don't need to specify this.
 * @param SchemaInputT - The TypeScript type representing the structure of the tool arguments generated by the LLM. Useful for type checking tool handler functions when using JSONSchema.
 */
interface ToolInterface<SchemaT = StringInputToolSchema, SchemaInputT = ToolInputSchemaInputType<SchemaT>, ToolOutputT = ToolOutputType> extends StructuredToolInterface<SchemaT, SchemaInputT, ToolOutputT> {
    /**
     * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
     *
     * Calls the tool with the provided argument and callbacks. It handles
     * string inputs specifically.
     * @param arg The input argument for the tool, which can be a string, undefined, or an input of the tool's schema.
     * @param callbacks Optional callbacks for the tool.
     * @returns A Promise that resolves with a string.
     */
    call<TArg extends StructuredToolCallInput<SchemaT, SchemaInputT>, TConfig extends ToolRunnableConfig | undefined>(arg: TArg, callbacks?: TConfig): Promise<ToolReturnType<NonNullable<TArg>, TConfig, ToolOutputT>>;
}
/**
 * Base interface for the input parameters of the {@link DynamicTool} and
 * {@link DynamicStructuredTool} classes.
 */
interface BaseDynamicToolInput extends ToolParams {
    name: string;
    description: string;
    /**
     * Whether to return the tool's output directly.
     *
     * Setting this to true means that after the tool is called,
     * an agent should stop looping.
     */
    returnDirect?: boolean;
}
/**
 * Interface for the input parameters of the DynamicTool class.
 */
interface DynamicToolInput<ToolOutputT = ToolOutputType> extends BaseDynamicToolInput {
    func: (input: string, runManager?: CallbackManagerForToolRun, config?: ToolRunnableConfig) => Promise<ToolOutputT>;
}

/**
 * Base class for Tools that accept input of any shape defined by a Zod schema.
 */
declare abstract class StructuredTool<SchemaT = ToolInputSchemaBase, SchemaOutputT = ToolInputSchemaOutputType<SchemaT>, SchemaInputT = ToolInputSchemaInputType<SchemaT>, ToolOutputT = ToolOutputType> extends BaseLangChain<StructuredToolCallInput<SchemaT, SchemaInputT>, ToolOutputT | ToolMessage> implements StructuredToolInterface<SchemaT, SchemaInputT, ToolOutputT> {
    abstract name: string;
    abstract description: string;
    abstract schema: SchemaT;
    /**
     * Whether to return the tool's output directly.
     *
     * Setting this to true means that after the tool is called,
     * an agent should stop looping.
     */
    returnDirect: boolean;
    verboseParsingErrors: boolean;
    get lc_namespace(): string[];
    /**
     * The tool response format.
     *
     * If "content" then the output of the tool is interpreted as the contents of a
     * ToolMessage. If "content_and_artifact" then the output is expected to be a
     * two-tuple corresponding to the (content, artifact) of a ToolMessage.
     *
     * @default "content"
     */
    responseFormat?: ResponseFormat;
    /**
     * Default config object for the tool runnable.
     */
    defaultConfig?: ToolRunnableConfig;
    constructor(fields?: ToolParams);
    protected abstract _call(arg: SchemaOutputT, runManager?: CallbackManagerForToolRun, parentConfig?: ToolRunnableConfig): Promise<ToolOutputT>;
    /**
     * Invokes the tool with the provided input and configuration.
     * @param input The input for the tool.
     * @param config Optional configuration for the tool.
     * @returns A Promise that resolves with the tool's output.
     */
    invoke<TInput extends StructuredToolCallInput<SchemaT, SchemaInputT>, TConfig extends ToolRunnableConfig | undefined>(input: TInput, config?: TConfig): Promise<ToolReturnType<TInput, TConfig, ToolOutputT>>;
    /**
     * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
     *
     * Calls the tool with the provided argument, configuration, and tags. It
     * parses the input according to the schema, handles any errors, and
     * manages callbacks.
     * @param arg The input argument for the tool.
     * @param configArg Optional configuration or callbacks for the tool.
     * @param tags Optional tags for the tool.
     * @returns A Promise that resolves with a string.
     */
    call<TArg extends StructuredToolCallInput<SchemaT, SchemaInputT>, TConfig extends ToolRunnableConfig | undefined>(arg: TArg, configArg?: TConfig, 
    /** @deprecated */
    tags?: string[]): Promise<ToolReturnType<TArg, TConfig, ToolOutputT>>;
}
/**
 * Base class for Tools that accept input as a string.
 */
declare abstract class Tool<ToolOutputT = ToolOutputType> extends StructuredTool<StringInputToolSchema, ToolInputSchemaOutputType<StringInputToolSchema>, ToolInputSchemaInputType<StringInputToolSchema>, ToolOutputT> implements ToolInterface<StringInputToolSchema, ToolInputSchemaInputType<StringInputToolSchema>, ToolOutputT> {
    schema: z.ZodEffects<z.ZodObject<{
        input: z.ZodOptional<z.ZodString>;
    }, "strip", z.ZodTypeAny, {
        input?: string | undefined;
    }, {
        input?: string | undefined;
    }>, string | undefined, {
        input?: string | undefined;
    }>;
    constructor(fields?: ToolParams);
    /**
     * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
     *
     * Calls the tool with the provided argument and callbacks. It handles
     * string inputs specifically.
     * @param arg The input argument for the tool, which can be a string, undefined, or an input of the tool's schema.
     * @param callbacks Optional callbacks for the tool.
     * @returns A Promise that resolves with a string.
     */
    call<TArg extends string | undefined | z.input<this["schema"]> | ToolCall, TConfig extends ToolRunnableConfig | undefined>(arg: TArg, callbacks?: TConfig): Promise<ToolReturnType<NonNullable<TArg>, TConfig, ToolOutputT>>;
}
/**
 * A tool that can be created dynamically from a function, name, and description.
 */
declare class DynamicTool<ToolOutputT = ToolOutputType> extends Tool<ToolOutputT> {
    static lc_name(): string;
    name: string;
    description: string;
    func: DynamicToolInput<ToolOutputT>["func"];
    constructor(fields: DynamicToolInput<ToolOutputT>);
    /**
     * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
     */
    call<TArg extends string | undefined | z.input<this["schema"]> | ToolCall, TConfig extends ToolRunnableConfig | undefined>(arg: TArg, configArg?: TConfig): Promise<ToolReturnType<NonNullable<TArg>, TConfig, ToolOutputT>>;
    /** @ignore */
    _call(input: string, // DynamicTool's _call specifically expects a string after schema transformation
    runManager?: CallbackManagerForToolRun, parentConfig?: ToolRunnableConfig): Promise<ToolOutputT>;
}

declare const executeTool: (config: FreestyleExecuteScriptParamsConfiguration & {
    apiKey: string;
}) => DynamicTool;

export { executeTool };
